{"meta":{"title":"SUGARMIX","subtitle":null,"description":"真正的大师，永远都怀着一颗学徒的心","author":"sugarmix","url":"https://blog.sugarmix.me"},"pages":[{"title":"关于我","date":"2017-06-25T15:57:12.000Z","updated":"2020-04-07T08:02:20.261Z","comments":true,"path":"about/index.html","permalink":"https://blog.sugarmix.me/about/index.html","excerpt":"","text":"Nothing"},{"title":"分类","date":"2017-06-25T15:55:23.000Z","updated":"2020-04-07T08:02:20.261Z","comments":false,"path":"categories/index.html","permalink":"https://blog.sugarmix.me/categories/index.html","excerpt":"","text":""},{"title":"标签云","date":"2017-06-25T15:45:40.000Z","updated":"2020-04-07T08:02:20.261Z","comments":false,"path":"tags/index.html","permalink":"https://blog.sugarmix.me/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"谈一谈交叉编译","slug":"20200407163610","date":"2020-04-07T08:36:11.000Z","updated":"2020-04-21T15:55:32.779Z","comments":true,"path":"20200407163610/","link":"","permalink":"https://blog.sugarmix.me/20200407163610/","excerpt":"最近在做一些跟软件跨平台相关的事情，对曾经一直以为高大上的交叉编译也有了初步的认识。至于为什么说高大上呢，编译这个词，就很神圣，毕竟《编译原理》不是用几天时间就可以高明白的东西。在编译前面再加一个更具迷惑性的交叉，就更让人摸不找头脑了。这篇文章主要谈一谈什么是交叉编译，以及在实践中遇到的一些小问题。","text":"最近在做一些跟软件跨平台相关的事情，对曾经一直以为高大上的交叉编译也有了初步的认识。至于为什么说高大上呢，编译这个词，就很神圣，毕竟《编译原理》不是用几天时间就可以高明白的东西。在编译前面再加一个更具迷惑性的交叉，就更让人摸不找头脑了。这篇文章主要谈一谈什么是交叉编译，以及在实践中遇到的一些小问题。 交叉编译首先简化编译的概念，这里不提编译预处理、词法分析、语法分析等等一系列的概念，因为我也不知道自己是不是真的懂这些东西，想了解这部分概念，可以去看编译原理相关的书籍。 这里把编译简单的理解为从一种字符串（例如C语言的源程序）到另一种字符串（与机器相关的二进制01字符串）的转化。 进行转化操作的，一般来说是一个软件（我们不应该忘记曾经在纸带上打孔的科学家们，他们将想法变成纸带上孔的过程，难道不是编译所做的事情吗），这个软件被称为编译器。 一般情况下，写一段C程序，通过运行在x86机器上的编译器，编译出一个可以在x86上运行的程序。 另一种情况，还是那一段C程序，通过运行在AArch64机器上的编译器，编译出一个可以在AArch64上运行的程序。 这体现了C语言良好的跨平台特性，一段代码只需要分别编译就可以在两种架构的设备上运行。 然而，假如你现在手上的AArch64的机器内存很小，没有硬盘，它能做的事情只是以很低的功耗运行一些小型的软件，或者以任何理由导致它没有运行起一个编译器的能力，而凑巧的是，你手头正好有一个可以用来编译的x86机器。（如果这个也没有，那你真的是太惨了） 现在第三种情况出现了 还是刚才那段C程序，通过运行在x86机器上的编译器，编译出一个可以在AArch64上运行的程序。 上面这个编译器，就被称为交叉编译器，这种情况，就被称为交叉编译。很显然，交叉编译器编译出的二进制文件没有办法在这台编译出它的机器上运行。 静态链接和动态链接当我开开心心的把编译好的软件（此处应该理解为可执行文件），放到AArch64机器上运行的时候，告诉我缺少lib*.so*。出现这种情况一般是在编译时链接进来的库文件在目标系统（就是那个啥都没有还想运行软件的系统）上缺失。一种方案是直接使用静态链接，这种方案不推荐。首要原因可以参考为什么我反对普遍地静态链接？-依云&#39;s Blog，其次是，静态链接你真不见得编译的过 ;-) 动态链接库的查找方式既然我们菜的没法通过静态链接，理智的接受了别人推荐的动态链接，那么就有必要知道二进制程序在运行时是如何查找所需要的链接库的。 直接放（在Linux可用的）结论。排名分先后 Linux中二进制文件使用ELF格式，其中包含RPATH变量，这个变量指向一个路径，这个路径是这个二进制文件查找so的路径。在链接时可以通过环境变量或者编译参数影响这个变量，这是最稳妥也最有效果的方式，但是需要在编译时就确定好目录，如果程序已经编译完了，懒得再次编译或者无法再次编译，就不能用这个方法了 如果上一个步骤没有找到链接库，同时又设置了LD_LIBRARY_PATH环境变量，那么会在这个环境变量指向的路径中查找。这是我个人最常用也最喜欢的方式，使用的时候甚至不需要export，而是直接加在命令前面，可以把影响范围缩小到仅一条命令 第三种是使用/etc/ld.so.conf，在第二种方式查找失败的时候会使用中指定的路径 除了第一种，剩下两种都有一定的约束条件，毕竟平白无辜设置一个环境变量二进制程序也不会去直接读。那么就要简单的说一下后两种是怎么生效的。在理解生效方式后，也就理解为什么也可以把so直接放到/lib或者/usr/lib里了。 算了，我懒了，这里直接贴man ld.so的输出 When resolving shared object dependencies, the dynamic linker first inspects each dependency string to see if it contains a slash (this can occur if a shared object pathname containing slashes was specified at link time). If a slash is found, then the dependency string is interpreted as a (relative or absolute) pathname, and the shared object is loaded using that pathname. If a shared object dependency does not contain a slash, then it is searched for in the following order: Using the directories specified in the DT_RPATH dynamic section attribute of the binary if present and DT_RUNPATH attribute does not exist. Use of DT_RPATH is deprecated. Using the environment variable LD_LIBRARY_PATH, unless the executable is being run in secure-execution mode (see below), in which case this variable is ignored. Using the directories specified in the DT_RUNPATH dynamic section attribute of the binary if present. Such directories are searched only to find those objects required by DT_NEEDED (direct dependencies) entries and do not apply to those objects&#39; children, which must themselves have their own DT_RUNPATH entries. This is unlike DT_RPATH, which is applied to searches for all children in the dependency tree. From the cache file /etc/ld.so.cache, which contains a compiled list of candidate shared objects previously found in the augmented library path. If, however, the binary was linked with the -z nodeflib linker option, shared objects in the default paths are skipped. Shared objects installed in hardware capability directories (see below) are preferred to other shared objects. In the default path /lib, and then /usr/lib. (On some 64-bit architectures, the default paths for 64-bit shared objects are /lib64, and then /usr/lib64.) If the binary was linked with the -z nodeflib linker option, this step is skipped. 其中，刷新/etc/ld.so.cache的是/sbin/ldconfig。 手册可真是个好东西呀，这篇文章只是粗略的描述了一下，需要了解细节可以通过手册一层一层的查下去了。 本文完。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.sugarmix.me/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://blog.sugarmix.me/tags/Linux/"}]},{"title":"RabbitMQ","slug":"20200215181709","date":"2020-02-15T10:17:22.000Z","updated":"2020-04-07T08:02:20.251Z","comments":true,"path":"20200215181709/","link":"","permalink":"https://blog.sugarmix.me/20200215181709/","excerpt":"RabbitMQ 的引导文档给出了大多数常用语言的样例代码，却没有C/C++的版本，大概用C/C++开发RabbitMQ的太少了？当然不能否认的是，最常用的Python版本底层也是C/C++。","text":"RabbitMQ 的引导文档给出了大多数常用语言的样例代码，却没有C/C++的版本，大概用C/C++开发RabbitMQ的太少了？当然不能否认的是，最常用的Python版本底层也是C/C++。 本文目的以尽可能小的篇幅，完整的描述RabbitMQ的相关概念。并且解释这些概念是如何在代码中体现的。所以这里不会提到关于服务器搭建的流程，有相关需求请参考其他文档。 相关概念生产者将带有标签的数据发送给消息中间件,消息中间件根据标签和某些规则把消息发送给消费者。 在RabbitMQ中，与生产者直接接触的部分叫Exchange，携带的标签被称为为Routing Key。与消费者直接接触的部分是Queue。 所以，生产者只需要发送带有Routing Key的Message到Exchange。消费者只需要固定接收某个Queue中的内容。 消息从Exchange到Queue的过程在RabbitMQ内部完成。 在一个消息被发送前，需要让RabbitMQ知道整个消息的路由过程，否则消息将被丢弃。这个路由过程可以在生产者中声明，也可以在消费者中声明。但是个人认为，让生产者消费者与消息中间件内部结构解耦合是个更好的策略，可以通过与生产者消费者完全无关的代码来声明消息的路由关系,如果不想用代码，甚至可以直接在RabbitMQ Management里用鼠标点几下声明。 此外还有几个与业务逻辑关系不大的概念，但是在使用的时候经常出现，这里做一下简单的介绍。 在创建完成RabbitMQ服务器后，默认有一个guest账户，这个账户可以访问一个名为/的Virtual Host。其中涉及了两个概念，Users和Virtual Hosts。User和Virtual Host可以独立创建，并且它们之间是多对多的关系。即一个用户可以拥有多个虚拟主机，一个虚拟主机也可以被多个用户拥有。 Channel:信道仅仅创建了客户端到Broker之间的连接后，客户端还是不能发送消息的。需要为每一个Connection创建Channel，AMQP协议规定只有通过Channel才能执行AMQP的命令。一个Connection可以包含多个Channel。之所以需要Channel，是因为TCP连接的建立和释放都是十分昂贵的，如果一个客户端每一个线程都需要与Broker交互，如果每一个线程都建立一个TCP连接，暂且不考虑TCP连接是否浪费，就算操作系统也无法承受每秒建立如此多的TCP连接，可以简单的理解为线程池中的一个个线程。 消息的发送接收与路由，与程序指定的Channel无关。 RabbitMQ Tutorials这个教程覆盖了RabbitMQ的几种基本应用场景。 &quot;Hello World!&quot; 一个生产者，一个消费者，一个队列queue，类型为headers的Exchange绑定到queue。生产者发送消息，消费者接收到消息并处理。如果设置为no_ack=1,那么进入queue的消息会轮流发送给所有的消费者。不管处理消息的快慢，每个消费者需要处理的消息一样多。这样可能导致处理慢的消费者一直在处理，而处理的快在消费者闲着。Work queues解决了这个问题。 Work queues 为了实现，“谁没事干就把工作给谁”的效果。需要进行以下处理。真实工作中这样对待员工的话，会让高效员工快速的成长，如果最终不能支付符合员工预期的薪水，这样优秀的员工必然跳槽。 设置qos，让消费者最多持有有限(这里是1)个没有确认的消息。1amqp_basic_qos(conn, channel, 0, /*prefetch_count*/ 1 , 0); 设置no_ack=0，收到ack前，消息保存在队列里。1amqp_basic_consume(conn, channel, queue, amqp_empty_bytes, 0, 0, /*no_ack*/ 0, amqp_empty_table); 处理完消息发送basic.ack，删除队列中的消息。1amqp_basic_ack(conn,channel,envelope.delivery_tag,0); Publish/Subscribe 这里介绍类型为Fanout Exchange。当消息被发送到这种Exchange时，所有绑定到这个Exchange的queue都将收到消息。fanout发送消息时完全忽略routing key和binding key。 这里第一次出现binding key的概念，binding key为Exchange与queue联系的一个字符串。在不同的Exchange类型中有不同的用途。 binding key 是为了方便记忆的一种叫法，它实际上被称为Exchange和queue之间的routing key。但是生产者发送消息时携带的也叫routing key，为了不引起歧义，这里单独给它命名。 Routing 这里介绍类型为Direct Exchange。当binding key精确等于routing key时，消息会发送到queue。Exchange与同一个queue之间可能存在多个不同名字的binding key。同时也存在名字相同的binding key指向不同的queue。 通过组合不同的routing key和binding key，可以实现比fanout更精细的控制。 Topics 对于上一部分内容，routing key和binding key完全一致才会转发，Topics Exchange则使用通配符，比Direct Exchange更加灵活。 Remote Procedure Call (RPC) 这部分没有新概念的引入。只是对RabbitMQ的一种应用。上面的例子中，生产者和消费者关系分明。但是对于RPC来说，每个部分即是生产者也是消费者。约定发送请求的一方为Client，处理的一方为Server。 Client需要把消息发送给Server所绑定的队列，Server从队列中拿到消息处理后通过另一个队列回传给Client。为了让Server知道Client的队列是什么，Client在发送消息的时候要携带自己所绑定的队列的标识，也就是所谓的reply_to字段。同时，Client在收到响应的时候，要跟自己发送的请求进行匹配，又占用了一个标识，也就是所谓的correlation_id字段。 对于其他语言，用Json保存上面的结构化信息是个不错的选择，但是对于C/C++，可能用Protocol Buffers是个更好的选择。 使用C语言实现的RPC DemoProtocol Buffers文件：代替Json，传输效率更高。RPC客户端：客户端传入一个整数。RPC服务端：服务端接受这个整数，加一后返回给客户端。 参考RabbitMQ基本概念rabbitMQ常见问题RabbitMQ Tutorialsrabbitmq-c examples - producer/consumer work queue not working ???","categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.sugarmix.me/categories/数据库/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"https://blog.sugarmix.me/tags/消息队列/"}]},{"title":"开始使用WireGuard","slug":"20200202210032","date":"2020-02-02T13:00:36.000Z","updated":"2020-04-07T08:02:20.251Z","comments":true,"path":"20200202210032/","link":"","permalink":"https://blog.sugarmix.me/20200202210032/","excerpt":"WireGuard是让人眼前一亮的VPN软件。最近尝试通过它来完成两个没有公网IP的机器的通信，作为使用SSH访问内网中的服务器的代替方案。","text":"WireGuard是让人眼前一亮的VPN软件。最近尝试通过它来完成两个没有公网IP的机器的通信，作为使用SSH访问内网中的服务器的代替方案。 WireGuard的介绍和使用方法可以参考WireGuard-ArchWiki。 对于WireGuard，所有设备的关系基本对等。所以下面约定。有公网IP的机器被称作S，另外两台普通机器为A，B S中设置两个Peer A和B。A和B的Peer仅需要设置S。 这样A和B机器就可以相互访问了。能做什么事情就可以发挥自己的想象力了。","categories":[{"name":"默认","slug":"默认","permalink":"https://blog.sugarmix.me/categories/默认/"}],"tags":[{"name":"默认","slug":"默认","permalink":"https://blog.sugarmix.me/tags/默认/"}]},{"title":"己亥年年终总结","slug":"20200131211617","date":"2020-01-31T13:16:24.000Z","updated":"2020-04-07T08:02:20.251Z","comments":true,"path":"20200131211617/","link":"","permalink":"https://blog.sugarmix.me/20200131211617/","excerpt":"这篇文章本应该写在2019年末或者2020年初，因为一些原因拖到了现在，在这个时间点写可能更有意义一些吧，毕竟新年的发展有些出人意料。曾经的计划也可能因为现在情况的发展而落空。","text":"这篇文章本应该写在2019年末或者2020年初，因为一些原因拖到了现在，在这个时间点写可能更有意义一些吧，毕竟新年的发展有些出人意料。曾经的计划也可能因为现在情况的发展而落空。 序2020年的我24岁，已经过了可以尽情试错的年龄。过去这一年经历足够丰富。认识新朋友，重新审视老朋友，也学到一些（长者没有告诉我的）人生的经验。 关于工作2019年是正式工作的第一年。离开学校前一份实习。离开学校后第一份工作坚持了将近4个月，再一次生病后毅然选择辞职。在一个多月后换到了现在这份工作。其间面试过一些公司。学到的一点小小的经验是，工作就是拿钱办事。公司的角度是要花更少的钱办更多的事，在公司拿不出你想要的薪资的时候，一般会画饼， 这个项目上线了就给你们涨工资 又或者打感情牌， 公司花钱培养你们几个月，刚学会就要走不好 对于画饼不多说，能不能吃下这个饼看自己的判断。这里主要说一下第二种。如果公司觉得在试用期学会就走人是公司的损失，完全可以降低试用期工资（如果还能招到人的话），或者及时调整薪资到与能力相匹配的水平。有些人倾向于向公司提出涨薪。但是也存在另一些人，他知道自己换家公司可以显著提高自己的工资，同时可以短时间忍耐工资略低于工作能力（忍耐的过程不考虑工作效率）。我更倾向于后者，毕竟要给那些想白嫖劳动力的人一些教训。教训就是上面提到的那句话， 公司花钱培养你们几个月，刚学会就要走不好 在考虑与工作相关的事情时，撇开所有情感因素。因为工作只是一场交易。交易追求公平，如果自认为有失公允，完全可以离开这场交易，毕竟在自己年老体弱（35岁）时，公司会是主动中断交易的一方，在自己还有选择的时候，不要放弃自己的权利。 关于学习持续学习可能是无产阶级唯一能平稳度过中年危机的方法。能否持续学习应该被当作考量一份工作好坏的重要因素。到目前位置我发现持续学习有两个（特别功利的）好处。 足够的知识可以当作面试谈判的砝码 离开公司后，更多的知识可以帮助自己更好的生存 思想境界的提升先不考虑，毕竟我不想过 种豆南山下，草盛豆苗稀。晨兴理荒秽，带月荷锄归。 的生活。 顺便说一下我现在的学习方法：LeetCode 和 经典图书。能与人实时互动的方式都不推荐，比如QQ群。 回看这一年，学习新东西最多的时候是实习和离职后。还需要平衡好学习和工作的时间，不能学习的工作，或者学习的内容不是自己喜欢的工作，要果断换掉。还好我只是耽误了3个月。 关于生活到2020-01-31 22:41新型冠状病毒确诊病例9811,疑似病例15238。我已经在家里呆了不知道多少天，希望这一切快点结束，回归到正常生活。 这篇文章拖到现在写就是因为，现在我空闲时间比较多。而在应该写这篇文章的时间，刚好是我离职的那段时间，那段时间在刷题看书，没有抽出时间来写。平时还是要常常抽出时间思考。常常独立思考实在是太重要了呀。 实习和工作结交了很多新朋友，让我也看到了更多不同的人生。沉淀下来的老朋友，绝对是一笔物质和精神上的双重财富。 实习那段时间，小A去我实习城市玩，一起玩了两天。小A离开的时候我竟然控制不住自己的情绪。 跟小B认识快有10年了吧，安安稳稳到现在还是朋友，我可真棒。 当初在学校，就知道跟小C可以谈心。但是我们第一次没有目的聊天竟然发生在毕业后。 小D必须有姓名，虽然这半年的接触不是很多（导致运动量下降太多），不过接下来又可以经常约出来玩了。 恢复平静吧，我想去吃火锅了，热干面也可以。","categories":[{"name":"默认","slug":"默认","permalink":"https://blog.sugarmix.me/categories/默认/"}],"tags":[{"name":"默认","slug":"默认","permalink":"https://blog.sugarmix.me/tags/默认/"}]},{"title":"关于C++迭代器的一些小技巧","slug":"20191205005932","date":"2019-12-04T16:59:38.000Z","updated":"2020-04-07T08:02:20.251Z","comments":true,"path":"20191205005932/","link":"","permalink":"https://blog.sugarmix.me/20191205005932/","excerpt":"在看C++入门时，看到了关于迭代器的一些使用小技巧，觉得很有必要记下来。可能也是因为我太菜才觉得这部分很有趣吧。","text":"在看C++入门时，看到了关于迭代器的一些使用小技巧，觉得很有必要记下来。可能也是因为我太菜才觉得这部分很有趣吧。 这一切都来源于C++入门的练习10.30 练习10.30使用流迭代器，sort和copy从标准流读取一个整数序列，将其排序，并将结果写到标准输出。 题目中并没有说按照什么顺序排序，为了复习一下lambda表达式和bind函数，不使用默认的sort排序规则。 1234567891011121314151617181920212223242526272829#include &lt;algorithm&gt;#include &lt;functional&gt;#include &lt;iostream&gt;#include &lt;iterator&gt;#include &lt;vector&gt;using namespace std;using namespace std::placeholders;bool is_smaller(const int &amp;a, const int &amp;b) &#123; return a &lt; b;&#125;int main() &#123; istream_iterator&lt;int&gt; is_it(cin), eof; ostream_iterator&lt;int&gt; os_it(cout, \" \"); vector&lt;int&gt; vec(is_it, eof); auto is_greater = bind(is_smaller, _2, _1); auto greater_lambda = [](const int &amp;a, const int &amp;b) -&gt; bool &#123; return a &gt; b;&#125;; // 效果相同的三种sort sort(vec.begin(), vec.end(), is_greater); sort(vec.begin(), vec.end(), greater_lambda); sort(vec.rbegin(), vec.rend()); copy(vec.begin(), vec.end(), os_it); return 0;&#125;","categories":[{"name":"C++","slug":"C","permalink":"https://blog.sugarmix.me/categories/C/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://blog.sugarmix.me/tags/C/"}]},{"title":"使用SSH访问内网中的服务器","slug":"20190909233016","date":"2019-09-09T15:30:24.000Z","updated":"2020-04-07T08:02:20.251Z","comments":true,"path":"20190909233016/","link":"","permalink":"https://blog.sugarmix.me/20190909233016/","excerpt":"这篇文章讨论在有公网服务器作为中继的条件下，如何通过SSH访问没有公网IP的服务器。","text":"这篇文章讨论在有公网服务器作为中继的条件下，如何通过SSH访问没有公网IP的服务器。 这篇文章使用尽可能少的参数以及尽可能多的端口号，使读者更容易理解操作流程。 阅读文章前，请确定能理解下面这句指令的含义，以及[]中的内容不存在时使用的默认值是什么。 1ssh [username@]host [-p port] 在外网服务器中的操作先从服务器开始。首先假设您已经通过上个命令登录到服务器。 1ssh -L 0.0.0.0:10000:localhost:20000 outer@localhost -p 50000 -L [bind_address:]port:host:hostport Specifies that connections to the given TCP port or Unix socket on the local (client) host are to be forwarded to the given host and port, or Unix socket, on the remote side. 简而言之，0.0.0.0:10000 收到的内容将被转发给localhost:20000。其他的参数与最开始的指令的含义相同。 这是一个正向代理的过程。此时，就需要让 20000 端口收到的数据转发给内网中的服务器。 在内网服务器中的操作在进行后续操作前，请确定内网服务器的SSH服务的端口号是30000。 1ssh -R 20000:localhost:30000 outer@12.34.56.78 -p 50000 -R [bind_address:]port:host:hostport Specifies that connections to the given TCP port or Unix socket on the remote (server) host are to be forwarded to the local side. 这样，外网服务器在 20000 端口接收到的数据将被转发到内网服务器的 30000 端口。使用第三台机器进行测试。 1ssh inner@12.34.56.78 -p 10000 优化直接使用上述方式运行的话，命令保持在前台，并且存在断线的风险。使用autossh和ssh参数配置实现断线重连 12autossh -M 0 -o \"ServerAliveInterval 60\" -o \"ServerAliveCountMax 3\" -fCNL ...autossh -M 0 -o \"ServerAliveInterval 60\" -o \"ServerAliveCountMax 3\" -fCNR ... 数据流向某SSH客户端，访问外网服务器的10000端口，10000端口将接收到的数据直接转发给外网服务器的20000端口，内网服务器在外网服务器上打开了20000端口，并将数据转发给了内网服务器的30000端口。 通过访问50000端口的SSH服务器软件控制数据流向。","categories":[{"name":"默认","slug":"默认","permalink":"https://blog.sugarmix.me/categories/默认/"}],"tags":[{"name":"默认","slug":"默认","permalink":"https://blog.sugarmix.me/tags/默认/"}]},{"title":"C++函数指针到UE4委托代理","slug":"20190821135227","date":"2019-08-21T05:52:29.000Z","updated":"2020-04-07T08:02:20.251Z","comments":true,"path":"20190821135227/","link":"","permalink":"https://blog.sugarmix.me/20190821135227/","excerpt":"Delegate: A type of variable storing a reference to a method with a particular signature, analogous to a function pointer","text":"Delegate: A type of variable storing a reference to a method with a particular signature, analogous to a function pointer 函数指针12345678910111213141516171819202122232425262728293031323334// demo#include &lt;iostream&gt;// f是一个函数，函数的参数是 int，返回值是指向函数的指针// 被指向的函数的参数和返回值分别是(int*,int) 和 intint(*f(int)) (int*, int);// 这个函数刚好符合上面的函数返回值的要求int fun(int*, int);int main()&#123; int a = 1, b = 1; // pf是一个指向函数的指针 // 被指向的函数的参数列表和返回值分别是，(int*,int) 和 int int(*pf) (int*, int) = &amp;fun; // int(*pf) (int*, int) = fun; 效果同上 std::cout&lt;&lt; pf(&amp;a, b)&lt;&lt;std::endl; // 2 std::cout &lt;&lt; ((*f(1))(&amp;a, b)) &lt;&lt; std::endl; // 1 2 // std::cout &lt;&lt; (f(1)(&amp;a, b)) &lt;&lt; std::endl; 效果同上&#125;int fun(int* a, int b)&#123; return *a + b;&#125;int(*f(int a)) (int* b, int c)&#123; std::cout &lt;&lt; a &lt;&lt; std::endl; return fun;&#125; UE4 委托代理Wiki里对委托(Delegate)的解释 a type of variable storing a reference to a method with a particular signature, analogous to a function pointer 1234567891011121314151617181920212223242526272829303132333435//OnlyDelegateTest.h#pragma once#include \"CoreMinimal.h\"#include \"UObject/NoExportTypes.h\"#include \"OnlyDelegateTest.generated.h\"DECLARE_DYNAMIC_MULTICAST_DELEGATE(FOnlyDelegateTestSignature);UCLASS(Blueprintable)class FAITHGAME_API UOnlyDelegateTest : public UObject&#123; GENERATED_BODY() public: UFUNCTION(BlueprintCallable, Category = \"DelegateTest\") static UOnlyDelegateTest* get_instance_ptr(); static UOnlyDelegateTest&amp; get_instance();private: static UOnlyDelegateTest* instance_;public: UFUNCTION(BlueprintCallable, Category = \"DelegateTest\") void execute_broadcast_in_cpp();public: virtual class UWorld* GetWorld() const override; UPROPERTY(Transient) UWorld * World; public: UPROPERTY(BlueprintAssignable, Category = \"DelegateTest\") FOnlyDelegateTestSignature OnlyTestDelegate;&#125;; 123456789101112131415161718192021222324252627282930// OnlyDelegateTest.cpp#include \"etc...\"#include \"OnlyDelegateTest.h\"// 类外定义静态变量UOnlyDelegateTest* UOnlyDelegateTest::instance_ = nullptr;UOnlyDelegateTest* UOnlyDelegateTest::get_instance_ptr()&#123; if (nullptr != instance_) return instance_; instance_ = NewObject&lt;UOnlyDelegateTest&gt;(); instance_-&gt;AddToRoot(); return instance_;&#125;UOnlyDelegateTest&amp; UOnlyDelegateTest::get_instance()&#123; return *get_instance_ptr();&#125;void UOnlyDelegateTest::execute_broadcast_in_cpp()&#123; OnlyTestDelegate.Broadcast();&#125;UWorld* UOnlyDelegateTest::GetWorld() const&#123; return World;&#125;","categories":[{"name":"默认","slug":"默认","permalink":"https://blog.sugarmix.me/categories/默认/"}],"tags":[{"name":"默认","slug":"默认","permalink":"https://blog.sugarmix.me/tags/默认/"}]},{"title":"Best Time to Buy and Sell Stock II","slug":"20190629005849","date":"2019-06-28T16:58:58.000Z","updated":"2020-04-07T08:02:20.251Z","comments":true,"path":"20190629005849/","link":"","permalink":"https://blog.sugarmix.me/20190629005849/","excerpt":"给定一个数组，它的第 i 个元素是一支给定股票第 i 天的价格。设计一个算法来计算你所能获取的最大利润。你可以尽可能地完成更多的交易（多次买卖一支股票）。注意：你不能同时参与多笔交易（你必须在再次购买前出售掉之前的股票）。","text":"给定一个数组，它的第 i 个元素是一支给定股票第 i 天的价格。设计一个算法来计算你所能获取的最大利润。你可以尽可能地完成更多的交易（多次买卖一支股票）。注意：你不能同时参与多笔交易（你必须在再次购买前出售掉之前的股票）。 如果获得收益，一定是低价买入，高价卖出。对于[1,2,3]，可以在第1天买入，在第3天卖出。但是也可以理解为，在第2天卖出，又在第2天买入。那么题目可以化简为，如果第i天的价格比第i-1天的价格高，则在第i-1天买入，第i天卖出，每次只考虑临近的两天。算法如下。 1234567public int maxProfit(int[] prices) &#123; int earn=0; for(int i=1;i&lt;prices.length;i++)&#123; earn+=prices[i]&gt;prices[i-1]?prices[i]-prices[i-1]:0; &#125; return earn;&#125; 补充Best Time to Buy and Sell Stock with Cooldown 在上述题目要求的基础上，又增加了一条要求 在股票卖出后不能直接再次进行交易 上面的算法不适用新情况，按照分治思想设计出的带有递归的算法复杂度超时，这里直接用前人给出的算法，当作记录和学习了 12345678910111213141516171819202122232425262728293031public int maxProfit(int[] prices) &#123; if (prices == null || prices.length &lt; 2) &#123; return 0; &#125; // 第i天持有股票获得的利润 int[] hold = new int[prices.length]; // 第i天不持有股票获得的利润 int[] unhold = new int[prices.length]; // 前两天如果持有股票，要买便宜的 hold[0] = -prices[0]; hold[1] = Math.max(-prices[0],-prices[1]); // 前两天如果不持有股票，要么是根本没买，要么是第一天买第二天卖并且赚了 unhold[0] = 0; unhold[1] = Math.max(0,prices[1]-prices[0]); for(int i=2;i&lt;prices.length;++i)&#123; // 第i天持有股票只有两种情况 // 保持第i-1天的持有情况不变 // 或者在i-2天卖出，并在第i天买入 // 注意:在i-2天保持未持有股票情况下的最大利润，并非一定在i-2天卖出了股票，下同 hold[i] = Math.max(hold[i-1],unhold[i-2]-prices[i]); // 第i天不持有股票的情况也有两种 // 保持i-1天的不持有情况不变 // 或者卖出在i-1天买入的股票 unhold[i] = Math.max(unhold[i-1],hold[i-1]+prices[i]); &#125; // 最后一天一定是不持有股票获得的利润最大 return unhold[prices.length-1];&#125; 由于数组每次都是使用的最近几个元素，算法可以优化到O(1)空间复杂度。 123456789101112131415161718192021public int maxProfit(int[] prices) &#123; if (prices == null || prices.length &lt; 2) &#123; return 0; &#125; int[] hold = new int[1]; int[] unhold = new int[3]; hold[0] = Math.max(-prices[0],-prices[1]); unhold[0] = 0; unhold[1] = Math.max(0,prices[1]-prices[0]); for(int i=2;i&lt;prices.length;++i)&#123; hold[0] = Math.max(hold[0],unhold[0]-prices[i]); unhold[2] = Math.max(unhold[1],hold[0]+prices[i]); unhold[0] = unhold[1]; unhold[1] = unhold[2]; &#125; return unhold[1];&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://blog.sugarmix.me/categories/算法/"}],"tags":[{"name":"数组","slug":"数组","permalink":"https://blog.sugarmix.me/tags/数组/"}]},{"title":"Maximum Subarray","slug":"20190627224513","date":"2019-06-27T14:45:23.000Z","updated":"2020-04-07T08:02:20.251Z","comments":true,"path":"20190627224513/","link":"","permalink":"https://blog.sugarmix.me/20190627224513/","excerpt":"给定一个整数数组 nums ，找到一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。","text":"给定一个整数数组 nums ，找到一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。 问题经典，曾见面试的时候写错了，这次又遇到，算是纪念一下曾经犯傻的自己吧。 123456789public int maxSubArray(int[] nums) &#123; int maxSum=nums[0]; int currentSum = nums[0]; for(int i=1;i&lt;nums.length;i++)&#123; currentSum=currentSum+nums[i]&gt;nums[i]?currentSum+nums[i]:nums[i]; maxSum=currentSum&gt;maxSum?currentSum:maxSum; &#125; return maxSum;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://blog.sugarmix.me/categories/算法/"}],"tags":[{"name":"数组","slug":"数组","permalink":"https://blog.sugarmix.me/tags/数组/"}]},{"title":"Find All Duplicates in an Array","slug":"20190625181705","date":"2019-06-25T10:17:16.000Z","updated":"2020-04-07T08:02:20.251Z","comments":true,"path":"20190625181705/","link":"","permalink":"https://blog.sugarmix.me/20190625181705/","excerpt":"给定一个整数数组 a，其中1 ≤ a[i] ≤ n （n为数组长度）, 其中有些元素出现两次而其他元素出现一次。 找到所有出现两次的元素。 你可以不用到任何额外空间并在O(n)时间复杂度内解决这个问题吗？","text":"给定一个整数数组 a，其中1 ≤ a[i] ≤ n （n为数组长度）, 其中有些元素出现两次而其他元素出现一次。 找到所有出现两次的元素。 你可以不用到任何额外空间并在O(n)时间复杂度内解决这个问题吗？ 题目中要求时间复杂度为O(n)，遍历整个数组的时间复杂度是O(n)，此外的所有操作时间复杂度都应该是O(1),使用哈系表可以满足时间复杂度。但是题目中还要求不使用额外的空间。也就意味着，不能使用哈系表，仅能在原数组上进行操作。 要求不使用额外空间，算法应该直接在原数组上进行操作，或者使用固定大小的内存(固定的几个变量，与输入数据规模无关)。将某个值放到其对应的指针的位置是常见的在原数组上进行的操作。扫描一遍数组，每个元素都修改一次某个变量，是常见的使用固定内存的方法。 时间复杂度O(n)，意味着只能对数组进行(固定次数的)扫描，毕竟O(n)=O(2n)=O(k*n)，其中k是与输入数据规模无关的常数。前几次扫描可以用来获取一些必要信息。比如判断单链表是否回文，可以通过第一次扫描确定单链表的长度。再通过第二次扫描反转一半的单链表。第三次扫描再判断是否回文。 这个题目扫描两次数组，第一次将值放到其对应的键上，并交换。第二次扫描，查找那些键值不匹配的位置的值，这些值就是要找的结果。 12345678910111213141516public List&lt;Integer&gt; findDuplicates(int[] nums) &#123; for(int i=1;i&lt;=nums.length;i++)&#123; while(nums[i-1]!=nums[nums[i-1]-1])&#123; int tmp = nums[nums[i-1]-1]; nums[nums[i-1]-1] = nums[i-1]; nums[i-1]=tmp; &#125; &#125; List&lt;Integer&gt; ans = new ArrayList&lt;&gt;(); for(int i=1;i&lt;=nums.length;i++)&#123; if(nums[i-1]!=i)&#123; ans.add(nums[i-1]); &#125; &#125; return ans;&#125; 上面这个题要求找出所有重复出现的数字。有一个类似的题目，要求找出消失的数字。整体算法一致，唯一不同的是整理结果时获取的值不同。 1234// 将ans.add(nums[i-1]);// 修改为ans.add(i);","categories":[{"name":"算法","slug":"算法","permalink":"https://blog.sugarmix.me/categories/算法/"}],"tags":[{"name":"数组","slug":"数组","permalink":"https://blog.sugarmix.me/tags/数组/"}]},{"title":"Divisor Game","slug":"20190623223142","date":"2019-06-23T14:31:53.000Z","updated":"2020-04-07T08:02:20.251Z","comments":true,"path":"20190623223142/","link":"","permalink":"https://blog.sugarmix.me/20190623223142/","excerpt":"这是一个在LeetCode被标记为Easy的题目，具体描述如下。 爱丽丝和鲍勃一起玩游戏，他们轮流行动。爱丽丝先手开局。最初，黑板上有一个数字 N 。在每个玩家的回合，玩家需要执行以下操作： 选出任一 x，满足 0 &lt; x &lt; N 且 N % x == 0 。 用 N - x 替换黑板上的数字 N 。 如果玩家无法执行这些操作，就会输掉游戏。只有在爱丽丝在游戏中取得胜利时才返回 True，否则返回 false。假设两个玩家都以最佳状态参与游戏。","text":"这是一个在LeetCode被标记为Easy的题目，具体描述如下。 爱丽丝和鲍勃一起玩游戏，他们轮流行动。爱丽丝先手开局。最初，黑板上有一个数字 N 。在每个玩家的回合，玩家需要执行以下操作： 选出任一 x，满足 0 &lt; x &lt; N 且 N % x == 0 。 用 N - x 替换黑板上的数字 N 。 如果玩家无法执行这些操作，就会输掉游戏。只有在爱丽丝在游戏中取得胜利时才返回 True，否则返回 false。假设两个玩家都以最佳状态参与游戏。 题目中的假设玩家都以最佳状态参与游戏，也就是说，某个玩家若能赢则必须赢，不存在放水的情况。 比如，初始状态N=4,Alice必定选择将数字替换成3(4-1),并获得游戏的胜利，而不会选择替换成2(4-2)。 先看一下这个题目的一般思路。 123456789101112131415161718public boolean divisorGame(int N) &#123; if(N==2)&#123; return true; &#125;else if(N==3)&#123; return false; &#125; for(int i=1;i&lt;N;i++)&#123; if(N%i==0)&#123; // 进行一次操作后存在让Bob一定失败的情况 if(divisorGame(N-i)==false)&#123; // Alice一定胜利 return true; &#125; &#125; &#125; // 若不能保证Alice一定胜利，那么Bob一定胜利。 return false;&#125; 这是一个常规的递归思路，但是这个算法超时，即使用了备忘录也会超时。 现在有两个思路： 把这个递归过程反过来，用动态规划 用数学方法推出一个公式。一开始就有这样一个想法，但是没有想出公式的样子 瞄了一眼其他人的算法。当数字为偶数时为真(Alice胜利)，奇数时为假(Bob胜利)。下面用数学归纳法证明。 初始状态：2为真，3为假。4存在因子1,4-1的状态为假，故4的状态为真。(前面的算法描述)5仅存在一个因子1，5-1=4状态为真，不存在为假的状态。故5的状态为假。 对于接下来的偶数，都可以将状态转换到比它小1的奇数，奇数状态为假，偶数状态必为真。 接下来要证明奇数的状态一定为假。奇数进行一次转换后必定为偶数。因为： 奇数减奇数一定为偶数。 奇数的因子一定是奇数 由因为偶数一定为真，故奇数一定为假。 123public boolean divisorGame(int N) &#123; return N%2==0;&#125; Divisor Game","categories":[{"name":"算法","slug":"算法","permalink":"https://blog.sugarmix.me/categories/算法/"}],"tags":[{"name":"数学","slug":"数学","permalink":"https://blog.sugarmix.me/tags/数学/"}]},{"title":"MySQL事务的并发问题与解决办法","slug":"20190327151300","date":"2019-03-27T07:13:00.000Z","updated":"2020-04-07T08:02:20.251Z","comments":true,"path":"20190327151300/","link":"","permalink":"https://blog.sugarmix.me/20190327151300/","excerpt":"本文阐述MySQL数据库多个事务并发时可能引发的问题，讨论MySQL事务不同的隔离级别是如何解决并发问题的，并简单了解不同隔离级别的实现方法。","text":"本文阐述MySQL数据库多个事务并发时可能引发的问题，讨论MySQL事务不同的隔离级别是如何解决并发问题的，并简单了解不同隔离级别的实现方法。 事务的并发问题 脏读：事务A对数据进行修改，提交。事务B读取到了事务A修改后，但还未提交的数据。读取到了一个不一定会提交的数据。 不可重复读：事务A对数据进行修改，提交。事务B共两次读取，第一次读取的结果为A修改前的数据，第二次读取的结果为A修改后的数据。两次读取的数据不一致。 幻读：事务A对数据进行批量操作，操作后查看操作结果。事务B在A操作后，查看结果前，提交一个插入操作。此时A查看操作结果发现存在没有被处理的数据。B的操作看起来没有被完全执行。 MySQL事务隔离级别通过事务不同的隔离级别解决不同的并发问题 事务隔离级别 脏读 不可重复读 幻读 解释 实现 read uncommitted 是 是 是 可以读未提交的数据 无特别操作 read committed 否 是 是 只能读已经提交的数据 对写入删除修改加行锁 repeatable read 否 否 否 可重复读 加行锁和间隙锁 serializable 否 否 否 串行化 加悲观锁 悲观锁和乐观锁 悲观锁读加共享锁，写加排他锁，读写互斥 乐观锁乐观锁，大多是基于数据版本（ Version ）记录机制实现。何谓数据版本？即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据库表增加一个 “version” 字段来实现。读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一。此时，将提交数据的版本数据与数据库表对应记录的当前版本信息进行比对，如果提交的数据版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据 InnoDB 如何实现可重复读对每行数据添加两个额外的版本记录，行创建版本号和行删除版本号。同时，每个事务有一个当前事务版本号。下文用create_version、delete_version、current_version代替上述三个版本号。 进行SELECT操作时，仅读取那些满足以下要求的数据 12(create_version &lt;= current_version) &amp;&amp; ((delete_version==null) || ( current_version &lt; delete_version)) INSERT时，保存当前事务版本号为行的创建版本号 DELETE时，保存当前事务版本号为行的删除版本号 UPDATE时，插入一条新纪录，保存当前事务版本号为行创建版本号，同时保存当前事务版本号到原来删除的行 测试建测试用的表 12345CREATE TABLE `test` ( `id` int(11) NOT NULL AUTO_INCREMENT, `content` varchar(45) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=latin1; READ UNCOMMITTED启动两个客户端，分别设置隔离级别为READ UNCOMMITTED并启动事务 12SET SESSION TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;START TRANSACTION B事务查表，返回空表 1Empty set (0.000 sec) A事务插入数据，不提交 1insert into test values(1,'abc'); 1Query OK, 1 row affected (0.001 sec) B事务查表，返回A未提交的数据，出现脏读 123456+----+---------+| id | content |+----+---------+| 1 | abc |+----+---------+1 row in set (0.000 sec) 提交两个事务，进入后续测试。 READ COMMITTED设置隔离级别为READ COMMITTED并开启事务 12SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED;START TRANSACTION; B查表，返回先前测试时插入的一条数据 123456+----+---------+| id | content |+----+---------+| 1 | abc |+----+---------+1 row in set (0.000 sec) A插入数据 1insert into test values(2,'def'); 1Query OK, 1 row affected (0.001 sec) A查表，获取到插入的数据 1234567+----+---------+| id | content |+----+---------+| 1 | abc || 2 | def |+----+---------+2 rows in set (0.000 sec) B查表，未获取到A未提交的数据，没有出现脏读 123456+----+---------+| id | content |+----+---------+| 1 | abc |+----+---------+1 row in set (0.000 sec) A提交1commit; B查表，返回A已提交的数据。在同一个事务中两次查询结果不一致，出现不可重复读。 1234567+----+---------+| id | content |+----+---------+| 1 | abc || 2 | def |+----+---------+2 rows in set (0.001 sec) B提交，进入后续测试 REPEATABLE READ设置隔离级别为REPEATABLE READ并开启事务 12SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;START TRANSACTION; A插入数据并提交 12insert into test values(3,'ghi');commit; B查表，并没有获取到A提交的数据，没有出现不可重复读。 1select * from test; 1234567+----+---------+| id | content |+----+---------+| 1 | abc || 2 | def |+----+---------+2 rows in set (0.000 sec) A 重新开启事务 1START TRANSACTION; A更新数据 1update test set content='000' where id &gt; 0; 12Query OK, 3 rows affected (0.035 sec)Rows matched: 3 Changed: 3 Warnings: 0 B插入数据，阻塞(等待A释放行锁)，超时报错(以下所有出现阻塞的情况，若不及时释放锁，均会出现超时错误) 1insert into test values(4,'jkl'); 1ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction A提交(释放行锁)1commit; B插入操作成功1insert into test values(4,'jkl'); 1Query OK, 1 row affected (17.265 sec) A，B查表获得结果分别如下 1234567+----+---------+| id | content |+----+---------+| 1 | 000 || 2 | 000 || 3 | 000 |+----+---------+ 12345678+----+---------+| id | content |+----+---------+| 1 | 000 || 2 | 000 || 3 | 000 || 4 | jkl |+----+---------+ 行锁可以防止不同事务版本的数据修改提交时造成数据冲突的情况。但如何避免别的事务插入数据就成了问题。行锁防止别的事务修改或删除，GAP锁(间隙锁)防止别的事务新增，行锁和GAP锁结合形成的Next-Key锁共同解决了REPEATABLE READ级别在写数据时的幻读问题 SERIALIZABLEREPEATABLE READ和SERIALIZABLE在使用中有什么区别呢。 12SET SESSION TRANSACTION ISOLATION LEVEL SERIALIZABLE;START TRANSACTION; A，B 读表返回结果相同(加共享锁)12345678+----+---------+| id | content |+----+---------+| 1 | 000 || 2 | 000 || 3 | 000 || 4 | jkl |+----+---------+ B 插入数据，阻塞(尝试加排它锁，等待A释放共享锁) 1update test set content='000' where id = 4; A回滚(释放共享锁)1rollback; B执行成功(成功获取排它锁)12Query OK, 1 row affected (7.354 sec)Rows matched: 1 Changed: 1 Warnings: 0 A再次开启事务，并进行查询操作,阻塞(尝试加共享锁，等待B释放排它锁) 1select * from test; B提交(释放排它锁) 1commit; 1Query OK, 0 rows affected (0.062 sec) A查表成功(成功获取共享锁)12345678+----+---------+| id | content |+----+---------+| 1 | 000 || 2 | 000 || 3 | 000 || 4 | 000 |+----+---------+ 在REPEATABLE READ级别，读写不互斥。 参考SET TRANSACTION SyntaxMySQL（二）｜深入理解MySQL的四种隔离级别及加锁实现原理","categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.sugarmix.me/categories/数据库/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://blog.sugarmix.me/tags/MySQL/"}]},{"title":"MySQL语句执行顺序简介","slug":"20190322155258","date":"2019-03-22T07:53:06.000Z","updated":"2020-04-07T08:02:20.251Z","comments":true,"path":"20190322155258/","link":"","permalink":"https://blog.sugarmix.me/20190322155258/","excerpt":"本篇文章侧重于一条SQL语句提交后，对于这条语句中不同部分的执行先后顺序，对于普通MySQL更实用。MySQL语句执行过程简介侧重于讲解底层的的原理。","text":"本篇文章侧重于一条SQL语句提交后，对于这条语句中不同部分的执行先后顺序，对于普通MySQL更实用。MySQL语句执行过程简介侧重于讲解底层的的原理。 首先给出如下语句，并对该语句的执行过程进行解释。 123456SELECT ...FROM ...WHERE ...GROUP BY ...HAVING ...ORDER BY ... 与SQL语句的书写顺序并不是一样的，而是按照下面的顺序来执行 FROM: 需要从哪个数据表检索数据 WHERE: 过滤表中数据的条件 GROUP BY: 如何将上面过滤出的数据分组 HAVING: 对上面已经分组的数据进行过滤的条件 SELECT: 查看结果集中的哪个列，或列的计算结果 ORDER BY: 按照什么样的顺序来查看返回的数据 FROMFROM后跟需要查询的表，可能是一个，也可能是多个。对于多个表的查询，不得不提到JOIN(连接)，能否合理使用JOIN也影响了执行效率的高低。 首先对给出连接操作的种类：交叉连接、内连接、外连接、自然连接和直接连接。 交叉连接123FROM table1,table2-- 等价于FROM table1 CROSS JOIN table2 交叉连接产生的是两个表的笛卡尔积，交叉链接可能产生巨大的表，慎用。 笛卡尔积：两个集合X和Y的笛卡尓积（Cartesian product），又称直积，表示为X × Y，第一个对象是X的成员而第二个对象是Y的所有可能有序对的其中一个成员 内连接12-- 一定要有 ONFROM table1 JOIN table2 ON table1.col1=table2.col2 如果不跟ON，则返回笛卡尔积。(与外链接没有区别吗？)ON可以被WHERE代替，但是ON效率更高。使用WHERE相当于先返回表格的笛卡尔积，再约束查询结果(猜测，带验证)。 外连接12345-- 一定显示table1中的所有行，若table2中没有与table1匹配的，则显示nullFROM table1 LEFT JOIN table2 on ...-- 一定显示table2中的所有行，若table1中没有与table2匹配的，则显示nullFROM table1 RIGHT JOIN table2 on ... 自然连接不允许指定ON，自动查找相同的列名进行连接。 直接连接12-- 强制以table1为基本表FROM table1 STRAIGHT_JOIN table2 其他参考手册中给出的关于JOIN有关的操作 12345678910111213141516171819202122232425262728293031323334353637383940table_references: escaped_table_reference [, escaped_table_reference] ...escaped_table_reference: table_reference | &#123; OJ table_reference &#125;table_reference: table_factor | joined_tabletable_factor: tbl_name [PARTITION (partition_names)] [[AS] alias] [index_hint_list] | table_subquery [AS] alias [(col_list)] | ( table_references )joined_table: table_reference &#123;[INNER | CROSS] JOIN | STRAIGHT_JOIN&#125; table_factor [join_specification] | table_reference &#123;LEFT|RIGHT&#125; [OUTER] JOIN table_reference join_specification | table_reference NATURAL [INNER | &#123;LEFT|RIGHT&#125; [OUTER]] JOIN table_factorjoin_specification: ON search_condition | USING (join_column_list)join_column_list: column_name [, column_name] ...index_hint_list: index_hint [, index_hint] ...index_hint: USE &#123;INDEX|KEY&#125; [FOR &#123;JOIN|ORDER BY|GROUP BY&#125;] ([index_list]) | &#123;IGNORE|FORCE&#125; &#123;INDEX|KEY&#125; [FOR &#123;JOIN|ORDER BY|GROUP BY&#125;] (index_list)index_list: index_name [, index_name] ... WHERE根据指定条件是否要将结果返回查询的表中。在MySQL索引中讲了一些WHERE的优化。此外对语句中的AND、OR、=也可以进行化简，这类化简属于数理逻辑内容，仅列出一个作为参考。 123(b&gt;=5 AND b=5) OR (b=6 AND 5=5) OR (b=7 AND 5=6)-- 化简为b=5 OR b=6 GROUP BY对结果分组 HAVING对上面已经分组的数据进行过滤的条件，此时是在被WHERE过滤后的表格进行操作，为了效率，尽可能的使用WHERE。若查询过程中出现聚合语句(SUM,MIN,MAX,AVG,COUNT)，则需要使用HAVING。 SELECT查看结果集中的哪个列，或列的计算结果。如果要显示的结果和查询过程中只使用了索引字段，则结果仅索引就可以返回，而不需要去查表。 ORDER BY按照什么样的顺序来查看返回的数据，排序操作必定消耗大量资源。 参考资料SQL语句执行顺序MySQL数据高级查询之连接查询、联合查询、子查询MySQL优化的奇技淫巧之STRAIGHT_JOINJOIN SyntaxMySQL优化器如何选择索引和JOIN顺序sql语句中WHERE与HAVING的区别","categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.sugarmix.me/categories/数据库/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://blog.sugarmix.me/tags/MySQL/"}]},{"title":"Edit Distance","slug":"20190321112352","date":"2019-03-21T03:24:00.000Z","updated":"2020-04-07T08:02:20.251Z","comments":true,"path":"20190321112352/","link":"","permalink":"https://blog.sugarmix.me/20190321112352/","excerpt":"存在两个字符串word1和word2，可以对word1进行插入、修改、删除某个字符的操作，最少经过多少次操作，可以让word1等于word2。","text":"存在两个字符串word1和word2，可以对word1进行插入、修改、删除某个字符的操作，最少经过多少次操作，可以让word1等于word2。 题目Given two words word1 and word2, find the minimum number of operations required to convert word1 to word2. You have the following 3 operations permitted on a word: Insert a character Delete a character Replace a character Example 1: Input: word1 = &quot;horse&quot;, word2 = &quot;ros&quot;Output: 3Explanation:horse -&gt; rorse (replace &#39;h&#39; with &#39;r&#39;)rorse -&gt; rose (remove &#39;r&#39;)rose -&gt; ros (remove &#39;e&#39;) Example 2: Input: word1 = &quot;intention&quot;, word2 = &quot;execution&quot;Output: 5Explanation:intention -&gt; inention (remove &#39;t&#39;)inention -&gt; enention (replace &#39;i&#39; with &#39;e&#39;)enention -&gt; exention (replace &#39;n&#39; with &#39;x&#39;)exention -&gt; exection (replace &#39;n&#39; with &#39;c&#39;)exection -&gt; execution (insert &#39;u&#39;) 分析虽然题目给出的操作方式是对word1的操作，但是word1的操作种类太多，首先尝试化简题目。word1的删除操作继续使用，不做讨论。word1的添加操作，可以视为对word2的删除操作。这两种操作都会使操作数+1,并且使两个word趋于一致。对于word1的修改操作，可以直接替换为同时删除word1和word2对应位置的字符。 现在题目被化简为，在两个word中进行删除操作，一次操作可以删除某一个或者两个都删除。经过一系列删除操作后，使得两个短字符串相同。可以得出状态转移方程为 1dp[m][n] = 1 + min(dp[m-1][n-1],dp[m-1][n],dp[m][n-1]) 其中m、n分别为指向两个字符串的指针，并且在到达dp[m][n]状态时，m、n指针前的字符串已经相同。 以上讨论都是对应字符不相同的情况，若字符相同，则保持操作数不变。 1dp[m][n] = dp[m-1][n-1] 最后还需要确定状态转移的初始条件。两个字符串都为空时，操作数为0，一个字符串为空，另一个字符串长度为i时，操作数为i，因为要完全删掉长字符串。 12dp[m][0]=mdp[0][n]=n 源码1234567891011121314151617181920212223242526package editdistance;public class Solution &#123; public int minDistance(String word1, String word2) &#123; int[][] dp = new int[word1.length() + 1][word2.length() + 1]; for (int m = 1; m &lt;= word1.length(); m++) &#123; dp[m][0] = m; &#125; for (int n = 1; n &lt;= word2.length(); n++) &#123; dp[0][n] = n; &#125; for (int m = 1; m &lt;= word1.length(); m++) &#123; for (int n = 1; n &lt;= word2.length(); n++) &#123; if (word1.charAt(m - 1) == word2.charAt(n - 1)) &#123; dp[m][n] = dp[m - 1][n - 1]; &#125; else &#123; dp[m][n] = 1 + Math.min(dp[m - 1][n - 1], Math.min(dp[m - 1][n], dp[m][n - 1])); &#125; &#125; &#125; return dp[word1.length()][word2.length()]; &#125;&#125; 总结这个题还是尝试去看别人的思路，但是无法理解添加和修改操作与状态转移方程之间的对应关系，所以从源码倒推思路，得到了上面对于题目化简的过程。曾经讨论对于字符串匹配题目可以使用滑动窗口，使用滑动窗口的时候是不考虑字符在字符串中的顺序的。如果字符串匹配有字符先后顺序的要求，那么就应该使用动态规划。 参考资料Edit DistanceJava DP solution - O(nm)","categories":[{"name":"算法","slug":"算法","permalink":"https://blog.sugarmix.me/categories/算法/"}],"tags":[{"name":"动态规划","slug":"动态规划","permalink":"https://blog.sugarmix.me/tags/动态规划/"}]},{"title":"Largest Rectangle in Histogram","slug":"20190320105022","date":"2019-03-20T02:50:23.000Z","updated":"2020-04-07T08:02:20.251Z","comments":true,"path":"20190320105022/","link":"","permalink":"https://blog.sugarmix.me/20190320105022/","excerpt":"一些紧密排列宽度为1高度已知(如2,1,5,6,2,3)的长方形，在这个拼出的图形中，寻找一个面积最大的长方形，返回这个长方形的面积。如本题中的5,6可拼出面积为10的长方形。","text":"一些紧密排列宽度为1高度已知(如2,1,5,6,2,3)的长方形，在这个拼出的图形中，寻找一个面积最大的长方形，返回这个长方形的面积。如本题中的5,6可拼出面积为10的长方形。 题目Given n non-negative integers representing the histogram&#39;s bar height where the width of each bar is 1, find the area of largest rectangle in the histogram. Example: 12Input: [2,1,5,6,2,3]Output: 10 思路整个思路来源于参考资料，把参考资料中的内容转化为自己容易理解的语言。对于每个长方形，必定存在左右边界，以及该边界对应的一个最大的高度。暴力搜索是一个思路，但是暴力搜索存在的一个缺陷是，有太多不必要的计算。比如输入数据为[1,2,3]，那么没有必要计算[1]和[1,2]这两种情况，这两种情况下，高度最高都是1,但是宽度却没有达到最大的3。存在这两个冗余的原因是没有确定一个合理的右界。若数组递增，则一定不会出现右界，所以右界出现在数组减小时。理论上，右界左边的都可以是左界，但是考虑[1,2,3,2,1],在3时出现第一次下降，右界为3。虽然此时可以计算[3]、[2,3]、[1,2,3],但是3的右面还存在2,当2成为边界时还会计算[2,3,2],所以边界为3时，没有必要计算[2,3]和[1,2,3]。所以确定左边界的条件是，左边界的极限值要大于右边界右面的值。左边界从右边界向左逐渐逼近左边界的极限，在这个过程中，左边界的高度始终为可以使用的最大高度，该高度逐渐下降。宽度则为左边界到有边界的间隔。根据边界和高度可以计算面积。左右边界各访问一次数组，时间复杂度为O(2n)=O(n)。 栈可以满足上面对左边界的描述。当右边界扩大时，将其入栈作为将来要使用的左边界。输入数据最后如果是个递增序列，递增的那部分就不会被考虑，右边界会扩展到最后而的不到左边界。在整个数组最后添加一个0使其最后一定不是一个递增序列。 同理，也应该在数组最开始位置添加一个0。但是可以使用数组为空时返回位置为-1解决这个问题。 123456789101112131415161718class Solution &#123; public int largestRectangleArea(int[] heights) &#123; int maxArea = 0; int[] tmp = new int[heights.length + 1]; System.arraycopy(heights, 0, tmp, 0, heights.length); heights = tmp; Stack&lt;Integer&gt; index = new Stack&lt;&gt;(); for (int i = 0; i &lt; heights.length; i++) &#123; while (!index.empty() &amp;&amp; heights[i] &lt; heights[index.peek()]) &#123; int h = heights[index.pop()]; int prev = index.empty() ? -1 : index.peek(); maxArea = Math.max(maxArea, (i - prev - 1) * h); &#125; index.push(i); &#125; return maxArea; &#125;&#125; 当然如果不理解为什么那样处理，可以依旧直接在开始添加0,对算法复杂度影响不大。 123456789101112131415161718class Solution &#123; public int largestRectangleArea(int[] heights) &#123; int maxArea = 0; int[] tmp = new int[heights.length + 2]; System.arraycopy(heights, 0, tmp, 1, heights.length); heights = tmp; Stack&lt;Integer&gt; index = new Stack&lt;&gt;(); for (int i = 0; i &lt; heights.length; i++) &#123; while (!index.empty() &amp;&amp; heights[i] &lt; heights[index.peek()]) &#123; int h = heights[index.pop()]; int prev = index.peek(); maxArea = Math.max(maxArea, (i - prev - 1) * h); &#125; index.push(i); &#125; return maxArea; &#125;&#125; 总结Java数组固定，不能在原数组后直接追加元素，只能创建一个大小比当前数组大的数组，复制数据，然后修改最后一个元素的值。数组初始化后默认值为0,所以不用修改。复制数组使用系统提供的数组复制方法。 123int[] tmp = new int[heights.length + 1];System.arraycopy(heights, 0, tmp, 0, heights.length);heights = tmp; 参考资料Largest Rectangle in HistogramO(n) stack c++ solution 12ms 中文详细解释","categories":[{"name":"算法","slug":"算法","permalink":"https://blog.sugarmix.me/categories/算法/"}],"tags":[{"name":"栈","slug":"栈","permalink":"https://blog.sugarmix.me/tags/栈/"},{"name":"Java数组复制","slug":"Java数组复制","permalink":"https://blog.sugarmix.me/tags/Java数组复制/"}]},{"title":"Minimum Window Substring","slug":"20190320093728","date":"2019-03-20T01:37:37.000Z","updated":"2020-04-07T08:02:20.251Z","comments":true,"path":"20190320093728/","link":"","permalink":"https://blog.sugarmix.me/20190320093728/","excerpt":"有两个字符串S和T，从S中找出一个最小的子串，该子串中包含T中的所有元素。如，当S=&quot;ADOBECODEBANC&quot;, T=&quot;ABC&quot;时，需要寻找的字串就为&quot;BANC&quot;。字符串T中的元素不要求按顺序出现在S中。","text":"有两个字符串S和T，从S中找出一个最小的子串，该子串中包含T中的所有元素。如，当S=&quot;ADOBECODEBANC&quot;, T=&quot;ABC&quot;时，需要寻找的字串就为&quot;BANC&quot;。字符串T中的元素不要求按顺序出现在S中。 题目Given a string S and a string T, find the minimum window in S which will contain all the characters in T in complexity O(n). Example: 12Input: S = &quot;ADOBECODEBANC&quot;, T = &quot;ABC&quot;Output: &quot;BANC&quot; Note: If there is no such window in S that covers all characters in T, return the empty string &quot;&quot;. If there is such window, you are guaranteed that there will always be only one unique minimum window in S. 分析根据题干描述可以看出，T虽然为一个字符串，但是其作用可以被当作一个Set/Map。因为某个字符在T中出现的位置不影响结果。如果每个字符仅出现一次，那么T就是一个集合。从S中寻找子串，可以使用滑动窗口，窗口要始终满足S中包含T这个限制。当新加入一个元素时，窗口右边界增大，直到满足限制。然后左边界，若左边界向右移动不破坏窗口的限制，则持续移动。左右窗口依次移动。最终确定窗口长度最小的字串。 错误版本认为T中元素不会重复导致的错误。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162class Solution &#123; public String minWindow(String s, String t) &#123; /* 滑动窗口的开始和结束位置 */ int begin = 0; int end = 0; /* 最终结果的开始和结束位置 */ int ansStart = 0; int ansEnd = 0; /* 当前最优解滑动窗口的大小 */ int ansLength = s.length(); /* 保存某个字符是否出现过 */ Map&lt;Character, Integer&gt; map = new HashMap(); for (char c : t.toCharArray()) &#123; /** * 遍历字符串T标记所有出现过的字符 * (c,0)表示字符c在当前滑动窗口出现的次数(0次) */ map.put(c, 0); &#125; char current_char; /* 滑动窗口 */ while (end &lt; s.length()) &#123; /** * map的值中包含0，表示T中有些字符还没出现在窗口 * 此时右移窗口右边界，直到所有字符均出现在窗口中 * 若右边界前的值是T中的字符，则该字符出现的次数+1 */ while (map.containsValue(0) &amp;&amp; end &lt; s.length()) &#123; current_char = s.charAt(end); if (map.containsKey(current_char)) &#123; map.put(current_char, map.get(current_char) + 1); &#125; end++; &#125; /** * map的值中不包含0,表示T中所有字符均出现在窗口中 * 此时右移窗口左边界，直到窗口中不包含完整的T，加上窗口前的一个刚好满足T的限制 * 若左边界的值是T中的字符，则该字符出现的次数-1 */ while (!map.containsValue(0) &amp;&amp; begin &lt; s.length()) &#123; current_char = s.charAt(begin); if (map.containsKey(current_char)) &#123; map.put(current_char, map.get(current_char) - 1); &#125; begin++; &#125; /* 此时是一个窗口，记录该窗口 */ if (end - begin &lt; ansLength) &#123; ansLength = end - begin; ansStart = begin - 1; // 注意开始位置要 -1 ansEnd = end; // 左闭右开，刚好不包含最后一个字符 &#125; &#125; if (ansStart == -1) &#123; return \"\"; &#125; else &#123; /* 左闭右开，刚好不包含最后一个字符 */ return s.substring(ansStart, ansEnd); &#125; &#125;&#125; 消除错误上个版本出现的错误是没有考虑某个字符在T中出现多次，使用0表示字符没有出现在窗口中，使用大于0的数字表示出现的次数。将记录方式反过来，可以消除这个错误。一开始就在Map中记录某个字符在T中出现的次数。若该字符出现在了窗口中，次数 -1 ，当次数小于等于0的时候，即表示T中所有字符均出现在窗口中。当存在大于0的值时移动右边界，否则移动左边界。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162class Solution &#123; private boolean maxValueOverZero(Map&lt;Character, Integer&gt; map) &#123; /* 判断是否存在大于0的值,存在则继续移动窗口右边界 */ for (Character character : map.keySet()) &#123; if (map.get(character) &gt; 0) &#123; return true; &#125; &#125; return false; &#125; public String minWindow(String s, String t) &#123; int begin = 0; int end = 0; int ansStart = 0; int ansEnd = 0; int ansLength = s.length(); Map&lt;Character, Integer&gt; map = new HashMap&lt;&gt;(); /* 把Map中的值初始化成在T中出现的次数 */ for (char c : t.toCharArray()) &#123; if (map.containsKey(c)) &#123; map.put(c, map.get(c) + 1); &#125; else &#123; map.put(c, 1); &#125; &#125; char current_char; while (end &lt; s.length()) &#123; while (this.maxValueOverZero(map) &amp;&amp; end &lt; s.length()) &#123; current_char = s.charAt(end); if (map.containsKey(current_char)) &#123; /* 注意：与前一个版本正好相反，这是里 -1 */ map.put(current_char, map.get(current_char) - 1); &#125; end++; &#125; while (!this.maxValueOverZero(map) &amp;&amp; begin &lt; s.length()) &#123; current_char = s.charAt(begin); if (map.containsKey(current_char)) &#123; map.put(current_char, map.get(current_char) + 1); &#125; begin++; &#125; if (end - begin &lt; ansLength) &#123; ansLength = end - begin; ansStart = begin - 1; ansEnd = end; &#125; &#125; if (ansStart == -1) &#123; return \"\"; &#125; else &#123; return s.substring(ansStart, ansEnd); &#125; &#125;&#125; 优化使用Map复杂度相对较大，可以使用数组代替Map,数组下表对应ASCII码(Map中的键)，数组值对应Map中的值。不清楚测试数据中的字符范围，直接使用完整的ASCII码(其实尝试过26、52，发现并不是只有字母) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859class Solution &#123; /* 代替Map的数组 */ private int[] chars = new int[128]; private boolean overZero() &#123; for (int i : chars) &#123; if (i &gt; 0) &#123; return true; &#125; &#125; return false; &#125; public String minWindow(String s, String t) &#123; int begin = 0; int end = 0; int ansStart = 0; int ansEnd = 0; int ansLength = s.length(); Set&lt;Character&gt; set = new HashSet&lt;&gt;(); for (char current_char : t.toCharArray()) &#123; chars[current_char] += 1; set.add(current_char); &#125; char current_char; while (end &lt; s.length()) &#123; while (this.overZero() &amp;&amp; end &lt; s.length()) &#123; current_char = s.charAt(end); if (set.contains(current_char)) &#123; chars[current_char] -= 1; &#125; end++; &#125; while (!this.overZero() &amp;&amp; begin &lt; s.length()) &#123; current_char = s.charAt(begin); if (set.contains(current_char)) &#123; chars[current_char] += 1; &#125; begin++; &#125; if (end - begin &lt; ansLength) &#123; ansLength = end - begin; ansStart = begin - 1; ansEnd = end; &#125; &#125; if (ansStart == -1) &#123; return \"\"; &#125; else &#123; return s.substring(ansStart, ansEnd); &#125; &#125;&#125; 总结使用数组代替键确定的Map可以降低算法复杂度。滑动窗口是一种思想，处理字符串匹配时优先考虑。没有给出输入数据范围时，算法需要考虑所有可能的情况。 参考资料Minimum Window Substring","categories":[{"name":"算法","slug":"算法","permalink":"https://blog.sugarmix.me/categories/算法/"}],"tags":[{"name":"滑动窗口","slug":"滑动窗口","permalink":"https://blog.sugarmix.me/tags/滑动窗口/"}]},{"title":"Super Egg Drop","slug":"20190315095242","date":"2019-03-15T01:52:51.000Z","updated":"2020-05-17T17:13:38.639Z","comments":true,"path":"20190315095242/","link":"","permalink":"https://blog.sugarmix.me/20190315095242/","excerpt":"鸡蛋从楼上掉下来，在某层以上一定会破，在某层以及以下一定不会破，若鸡蛋破碎则不能再次使用，现在有K个鸡蛋N层楼，每次可以在某层楼扔一个鸡蛋探测，在最坏的情况下，至少需要多少次才能准确探测出在第几层鸡蛋会破碎？","text":"鸡蛋从楼上掉下来，在某层以上一定会破，在某层以及以下一定不会破，若鸡蛋破碎则不能再次使用，现在有K个鸡蛋N层楼，每次可以在某层楼扔一个鸡蛋探测，在最坏的情况下，至少需要多少次才能准确探测出在第几层鸡蛋会破碎？ 题目You are given K eggs, and you have access to a building with N floors from 1 to N.Each egg is identical in function, and if an egg breaks, you cannot drop it again.You know that there exists a floor F with 0 &lt;= F &lt;= N such that any egg dropped at a floor higher than F will break, and any egg dropped at or below floor F will not break.Each move, you may take an egg (if you have an unbroken one) and drop it from any floor X (with 1 &lt;= X &lt;= N).Your goal is to know with certainty what the value of F is.What is the minimum number of moves that you need to know with certainty what F is, regardless of the initial value of F? 正面解决即根据题目意思直接计算 F 暴力破解可以确定算法正确。 1234567891011121314151617181920212223public class Solution &#123; public int superEggDrop(int K, int N) &#123; int t; if (K == 0 || N == 0) &#123; /* 没有鸡蛋或者没有楼层的时候肯定是 0 */ return 0; &#125; else if (K == 1) &#123; /* 仅有一个鸡蛋，只能从最底层开始尝试，有几层就要尝试几次 */ return N; &#125; else &#123; /* 尝试最底层，如果鸡蛋没碎，确定结果；如果鸡蛋碎了，则问题转化为，K-1个鸡蛋探索N-1个楼层 */ t = Math.max(this.superEggDrop(K, 0), this.superEggDrop(K - 1, N - 1)); for (int i = 1; i &lt; N; i++) &#123; /* * 尝试第i+1层，如果鸡蛋没碎，则问题转化为K个鸡蛋探索i层，即第一层到第i层(i-1+1)； * 如果鸡蛋碎了，则问题转化为，K-1个鸡蛋探索N-i-1个楼层，即第i+2层到N层(N-(i+2)+1)； */ t = Math.min(t, Math.max(this.superEggDrop(K, i), this.superEggDrop(K - 1, N - i - 1))); &#125; &#125; return t + 1; &#125;&#125; K=3,N=26 不出意外的超时了。 备忘录分析上述算法超时的原因，存在太多重复的递归运算，使用备忘录消除重复计算。 123456789101112131415161718192021222324public class Solution &#123; /* 备忘录 */ private int[][] note = new int[101][10001]; public int superEggDrop(int K, int N) &#123; int t; if (K == 0 || N == 0) &#123; return 0; &#125; else if (K == 1) &#123; return N; &#125; else if (this.note[K][N] != 0) &#123; /* 如果曾经计算过直接返回 */ return this.note[K][N]; &#125; else &#123; t = Math.max(this.superEggDrop(K, 0), this.superEggDrop(K - 1, N - 1)); for (int i = 1; i &lt; N; i++) &#123; t = Math.min(t, Math.max(this.superEggDrop(K, i), this.superEggDrop(K - 1, N - i - 1))); &#125; &#125; /* 返回前保存计算的值 */ this.note[K][N] = t + 1; return t + 1; &#125;&#125; K=6,N=2000 原本以为这样可以不优雅的通过，然而却依旧超时。 消除递归上述算法虽然消除了重复的递归运算，但依旧存在大量递归，递归本身消耗的时间太多，使用动态规划填表的方式消除递归。 1234567891011121314151617181920212223242526272829public class Solution &#123; public int superEggDrop(int K, int N) &#123; /* 二维数组初始值为0 */ int[][] table = new int[K + 1][N + 1]; for (int i = 1; i &lt;= N; i++) &#123; /* 初始化1个鸡蛋i层楼尝试i次的情况 */ table[1][i] = i; &#125; for (int i = 1; i &lt;= K; i++) &#123; /* 初始化i个鸡蛋在1层楼尝试1次的情况 */ table[i][1] = 1; &#125; /* 开始填表，思路同递归算法 */ for (int k = 2; k &lt;= K; k++) &#123; for (int n = 2; n &lt;= N; n++) &#123; int t = Math.max(table[k][0], table[k - 1][n - 1]); for (int i = 1; i &lt; n; i++) &#123; t = Math.min(t, Math.max(table[k][i], table[k - 1][n - i - 1])); &#125; table[k][n] = t + 1; &#125; &#125; return table[K][N]; &#125;&#125; K=7,N=10000 意外的超时了。 减少遍历此处存在大量无价值的遍历，考虑到随着i增加，table[k][i],table[k - 1][n - i - 1]分别单调增加和减少，故其两个中较大值，一定出现在中间位置。可以使用二分法找出最合适的i。 123for (int i = 1; i &lt; n; i++) &#123; t = Math.min(t, Math.max(table[k][i], table[k - 1][n - i - 1]));&#125; 另一个思路K个鸡蛋，尝试M次，最多可以尝试到的楼层个数为table[K][M]。尝试某一层，若在该层碎了，则使用K-1个鸡蛋探索M-1次，若没碎，使用K个鸡蛋探索M-1次，当前探索的本层为1。虽然不知道尝试的哪一层，但是知道存在某一层，尝试后会得到的结果为table[K][M]。当 table[k][m-1] &lt; F &lt;= table[k][m] 时，m即为探索的次数，注意鸡蛋可能给多了所以使用k而不是K，其中k&lt;=K。此时需要预估最大尝试次数M。 123456789101112131415161718192021222324252627282930313233343536373839public class Solution &#123; public int superEggDrop(int K, int N) &#123; int M = N; int i, j; int[][] table = new int[K + 1][M + 1]; for (i = 1; i &lt;= M; i++) &#123; /* 1个鸡蛋尝试i次 */ table[1][i] = i; &#125; for (j = 1; j &lt;= K; j++) &#123; /* j个鸡蛋尝试1次 */ table[j][1] = 1; &#125; /** * 策略是：尽可能的多使用鸡蛋，少使用尝试次数 * 故遍历时，内层遍历鸡蛋，让鸡蛋先用完， * 外层遍历尝试次数，不得已的时候增加尝试次数 */ for (i = 2; i &lt;= M; i++) &#123; for (j = 2; j &lt;= K; j++) &#123; table[j][i] = table[j - 1][i - 1] + table[j][i - 1] + 1; if (table[j][i] &gt;= N) &#123; return i; &#125; &#125; &#125; /** * 楼层数为1,或鸡蛋数为1时会走到这里 * 楼层数为1时返回1，鸡蛋数为1时返回楼层数 * 综上返回楼层数即可 * */ return N; &#125;&#125; Accepted 总结至此，问题终于解决。最棒的情况是可以独立快速的解决问题，在认真思考后依旧不能给出合适的答案时，寻求帮助也是个不错的选择。 参考资料Super Egg DropLeetcode 887 Super Egg Drop(扔鸡蛋) DPSuper Egg Drop Solution","categories":[{"name":"算法","slug":"算法","permalink":"https://blog.sugarmix.me/categories/算法/"}],"tags":[{"name":"动态规划","slug":"动态规划","permalink":"https://blog.sugarmix.me/tags/动态规划/"}]},{"title":"MySQL语句执行过程简介","slug":"20190301160919","date":"2019-03-01T08:09:19.000Z","updated":"2020-04-07T08:02:20.251Z","comments":true,"path":"20190301160919/","link":"","permalink":"https://blog.sugarmix.me/20190301160919/","excerpt":"昔日庖丁解牛，未见全牛，所赖者是其对牛内部骨架结构的了解，对于MySQL亦是如此，只有更加全面地了解SQL语句执行的每个过程，才能更好的进行SQL的设计和优化。 当希望MySQL能够以更高的性能运行查询时，最好的办法就是弄清楚MySQL是如何优化和执行查询的。一旦理解了这一点，很多查询优化工作实际上就是遵循一些原则能够按照预想的合理的方式运行。","text":"昔日庖丁解牛，未见全牛，所赖者是其对牛内部骨架结构的了解，对于MySQL亦是如此，只有更加全面地了解SQL语句执行的每个过程，才能更好的进行SQL的设计和优化。 当希望MySQL能够以更高的性能运行查询时，最好的办法就是弄清楚MySQL是如何优化和执行查询的。一旦理解了这一点，很多查询优化工作实际上就是遵循一些原则能够按照预想的合理的方式运行。 总述如下图所示，当向MySQL发送一个请求的时候，MySQL到底做了什么： 客户端发送一条查询给服务器。 服务器先检查查询缓存，如果命中了缓存，则立刻返回存储在缓存中的结果。否则进入下一阶段。 服务器端进行SQL解析、预处理，再由优化器生成对应的执行计划。 MySQL根据优化器生成的执行计划，再调用存储引擎的API来执行查询。 将结果返回给客户端。 查询缓存MySQL查询缓存保存查询返回的完整结构。当查询命中该缓存时，MySQL会立刻返回结果，跳过了解析、优化和执行阶段查询缓存系统会跟踪查询中涉及的每个表，如果这些表发生了变化，那么和这个表相关的所有缓存数据都将失效。MySQL将缓存存放在一个引用表中，通过一个哈希值引用，这个哈希值包括了以下因素，即查询本身、当前要查询的数据库、客户端协议的版本等一些其他可能影响返回结果的信息。当判断缓存是否命中时，MySQL不会进行解析查询语句，而是直接使用SQL语句和客户端发送过来的其他原始信息。所以，任何字符上的不同，例如空格、注解等都会导致缓存的不命中。当查询语句中有一些不确定的数据时，则不会被缓存。例如包含函数NOW()或者CURRENT_DATE()的查询不会缓存。包含任何用户自定义函数，存储函数，用户变量，临时表，mysql数据库中的系统表或者包含任何列级别权限的表，都不会被缓存。有一点需要注意，MySQL并不是会因为查询中包含一个不确定的函数而不检查查询缓存，因为检查查询缓存之前，MySQL不会解析查询语句，所以也无法知道语句中是否有不确定的函数。事实则是，如果查询语句中包含任何的不确定的函数，那么其查询结果不会被缓存，因为查询缓存中也无法找到对应的缓存结果。有关查询缓存的配置如下所示。 query_cache_type:是否打开查询缓存。可以设置为OFF、ON和DEMAND。DEMAND表示只有在查询语句中明确写明SQL_CACHE的语句才会放入查询缓存。 query_cache_size:查询缓存使用的总内存空间。 query_cache_min_res_unit:在查询缓存中分配内存块时的最小单元。较小的该值可以减少碎片导致的内存空间浪费，但是会导致更频繁的内存块操作。 query_cache_limit:MySQL能够查询的最大查询结果。如果查询结果大于这个值，则不会被缓存。因为查询缓存在数据生成的时候就开始尝试缓存数据，所以当结果全部返回后，MySQL才知道查询结果是否超出限制。超出之后，才会将结果从查询缓存中删除。 解析和预处理解析器通过关键字将SQL语句进行解析，并生成对应的解析树。MySQL解析器将使用MySQL语法规则验证和解析查询。预处理器则根据一些MySQL规则进行进一步检查解析书是否合法，例如检查数据表和数据列是否存在，还会解析名字和别名，看看它们是否有歧义。 查询优化器查询优化器会将解析树转化成执行计划。一条查询可以有多种执行方法，最后都是返回相同结果。优化器的作用就是找到这其中最好的执行计划。生成执行计划的过程会消耗较多的时间，特别是存在许多可选的执行计划时。如果在一条SQL语句执行的过程中将该语句对应的最终执行计划进行缓存，当相似的语句再次被输入服务器时，就可以直接使用已缓存的执行计划，从而跳过SQL语句生成执行计划的整个过程，进而可以提高语句的执行速度。 MySQL使用基于成本的查询优化器(Cost-Based Optimizer，CBO)。它会尝试预测一个查询使用某种执行计划时的成本，并选择其中成本最少的一个。 优化器会根据优化规则对关系表达式进行转换，这里的转换是说一个关系表达式经过优化规则后会生成另外一个关系表达式，同时原有表达式也会保留，经过一系列转换后会生成多个执行计划，然后CBO会根据统计信息和代价模型(Cost Model)计算每个执行计划的Cost，从中挑选Cost最小的执行计划。由上可知，CBO中有两个依赖：统计信息和代价模型。统计信息的准确与否、代价模型的合理与否都会影响CBO选择最优计划。 查询执行引擎在解析和优化阶段，MySQL将生成查询对应的执行计划，MySQL的查询执行引擎根据这个执行计划来完成整个查询。这里执行计划是一个数据结构，而不是和其他的关系型数据库那样生成对应的字节码。 返回结果给客户端如果查询可以被缓存，那么MySQL在这个阶段页会将结果存放到查询缓存中。MySQL将结果集返回给客户端是一个增量、逐步返回的过程。在查询生成第一条结果时，MySQL就可以开始向客户端逐步返回结果集了。 原文链接SQL语句执行过程详解","categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.sugarmix.me/categories/数据库/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://blog.sugarmix.me/tags/MySQL/"},{"name":"转载","slug":"转载","permalink":"https://blog.sugarmix.me/tags/转载/"}]},{"title":"MySQL索引","slug":"20190226104504","date":"2019-02-26T02:45:05.000Z","updated":"2020-04-07T08:02:20.251Z","comments":true,"path":"20190226104504/","link":"","permalink":"https://blog.sugarmix.me/20190226104504/","excerpt":"索引用于快速查找具有特定列值的行。如果没有索引，MySQL必须从第一行开始，然后读取整个表以查找相关行。表越大，成本越高。如果表中有相关​​列的索引，MySQL可以快速确定要在数据文件中间寻找的位置，而无需查看所有数据。这比按顺序读取每一行要快得多。本文将介绍如何使用索引，以及索引是如何工作的。","text":"索引用于快速查找具有特定列值的行。如果没有索引，MySQL必须从第一行开始，然后读取整个表以查找相关行。表越大，成本越高。如果表中有相关​​列的索引，MySQL可以快速确定要在数据文件中间寻找的位置，而无需查看所有数据。这比按顺序读取每一行要快得多。本文将介绍如何使用索引，以及索引是如何工作的。 大多数MySQL索引(PRIMARY KEY，UNIQUE，INDEX和FULLTEXT)都存储在B树中。例外：空间数据类型的索引使用R树;MEMORY表支持hash indexes;InnoDB的FULLTEXT索引使用inverted lists。 B-Tree索引和Hash索引对比了解B树和哈希数据结构有助于预测不同查询在索引中使用这些数据结构的不同存储引擎上的执行情况，特别是对于允许您选择B树或哈希索引的MEMORY存储引擎。 B-Tree索引的特点B树索引可用于使用 =，&gt;，&gt; =，&lt;，&lt;=或 BETWEEN 运算符的表达式中的列比较。如果 LIKE 的参数是不以通配符开头的常量字符串，则索引也可用于 LIKE 比较。例如，以下 SELECT 语句使用索引： 12SELECT * FROM tbl_name WHERE key_col LIKE 'Patrick%';SELECT * FROM tbl_name WHERE key_col LIKE 'Pat%_ck%'; 在第一个语句中，只考虑带有 &#39;Patrick&#39;&lt;= key_col &lt;&#39;Patrick&#39; 的行。在第二个语句中，仅考虑具有 &#39;Pat&#39;&lt;= key_col &lt;&#39;Pau&#39; 的行。 以下 SELECT 语句不使用索引： 12SELECT * FROM tbl_name WHERE key_col LIKE '%Patrick%';SELECT * FROM tbl_name WHERE key_col LIKE other_col; 在第一个语句中，LIKE 值以通配符开头。在第二个语句中，LIKE 值不是常量。 如果您使用... LIKE &#39;%string%&#39; 且 string 超过三个字符，MySQL使用Turbo Boyer-Moore算法初始化字符串的模式，然后使用此模式更快地执行搜索。 如果 col_name 被索引，则使用 col_name IS NULL 的搜索使用索引。 不跨越 WHERE 子句中所有 AND 级别的任何索引不用于优化查询。换句话说，为了能够使用索引，必须在每个 AND 组中使用索引的前缀(被 OR 分割的短语中，至少要有一个子句使用索引前缀)。 以下 WHERE 子句使用索引： 12345678910SELECT * FROM tbl_name WHERE index_part1=1 AND index_part2=2 AND other_column=3/* index = 1 OR index = 2 */SELECT * FROM tbl_name WHERE index=1 OR A=10 AND index=2/* optimized like \"index_part1='hello'\" */SELECT * FROM tbl_name WHERE index_part1='hello' AND index_part3=5/* Can use index on index1 but not on index2 or index3 */SELECT * FROM tbl_name WHERE index1=1 AND index2=2 OR index1=3 AND index3=3; 以下 WHERE 子句不使用索引 12345678/* index_part1 is not used */SELECT * FROM tbl_name WHERE index_part2=1 AND index_part3=2/* Index is not used in both parts of the WHERE clause */SELECT * FROM tbl_name WHERE index=1 OR A=10/* No index spans all rows */SELECT * FROM tbl_name WHERE index_part1=1 OR index_part2=10 有时候，即使存在索引，MySQL也不使用索引。比如，当优化器预计使用索引将扫描表格中大多数的行(在这种情况下，表扫描可能会快得多，因为它需要较少的搜索)时，就不使用索引。如果查询中使用 LIMIT 获取结果中的一部分，则一定会使用索引，因为仅查找很少的几行，使用索引速度更快。 Hash索引的特点散列索引与刚才讨论的特征有些不同： 它们仅用于使用=或&lt;=&gt;运算符的相等比较(但速度非常快)。它们不用于比较运算符，例如，使用 &lt; 查找到一系列值。依赖于这种类型的单值查找的系统被称为“键值存储”;要将MySQL用于此类应用程序，请尽可能使用哈希索引。 优化器无法使用哈希索引来加速 ORDER BY 操作。(此类索引不能用于按顺序搜索下一个条目。) MySQL无法确定两个值之间大约有多少行(范围优化器使用它来决定使用哪个索引)。如果将MyISAM或InnoDB表更改为哈希索引的MEMORY表，则可能会影响某些查询。 只有整个键可用于搜索行。(使用B树索引，键的任何最左边的前缀都可用于查找行。) 多列索引MySQL可以创建复合索引(即多列索引)。索引最多可包含16列。对于某些数据类型，您可以索引列的前缀。 MySQL可以对测试索引中所有列的查询使用多列索引，或者只测试第一列，前两列，前三列等的查询。如果在索引定义中以正确的顺序指定列，则单个复合索引可以加速同一表上的多种查询。 多列索引可以视为排序数组，其行包含通过连接索引列的值创建的值。 笔记作为复合索引的替代方法，您可以根据其他列的信息引入“散列”列。如果此列很短，相当独特且已编制索引，则它可能比许多列上的“宽”索引更快。在MySQL中，使用这个额外的列很容易：123SELECT * FROM tbl_name WHERE hash_col=MD5(CONCAT(val1,val2)) AND col1=val1 AND col2=val2; 假设一个表具有以下规范： 1234567CREATE TABLE test ( id INT NOT NULL, last_name CHAR(30) NOT NULL, first_name CHAR(30) NOT NULL, PRIMARY KEY (id), INDEX name (last_name,first_name)); name索引是last_name和first_name列的索引。该索引可用于查询中的查找，这些查询为last_name和first_name值的组合指定已知范围内的值。它还可以用于仅指定last_name值的查询，因为该列是索引的最左前缀。因此，名称索引用于以下查询中的查找： 123456789101112SELECT * FROM test WHERE last_name='Widenius';SELECT * FROM test WHERE last_name='Widenius' AND first_name='Michael';SELECT * FROM test WHERE last_name='Widenius' AND (first_name='Michael' OR first_name='Monty');SELECT * FROM test WHERE last_name='Widenius' AND first_name &gt;='M' AND first_name &lt; 'N'; 但是，name索引不用于以下查询中的查找： 1234SELECT * FROM test WHERE first_name='Michael';SELECT * FROM test WHERE last_name='Widenius' OR first_name='Michael'; 假设您发出以下SELECT语句： 12SELECT * FROM tbl_name WHERE col1=val1 AND col2=val2 如果col1和col2上存在多列索引，则可以直接获取相应的行。如果col1和col2上存在单独的单列索引，则优化程序会尝试使用索引合并优化。或者尝试通过确定哪个索引排除更多行并使用该索引来获取行来查找限制性最强的索引。 如果表具有多列索引，则优化程序可以使用索引的任何最左前缀来查找行。例如，如果在(col1，col2，col3)上有三列索引，则在(col1)，(col1，col2)和(col1，col2，col3)上可以使用索引搜索功能。 如果列不形成索引的最左前缀，则MySQL无法使用索引执行查找。假设您有这里显示的SELECT语句： 1234567/* use the index. */SELECT * FROM tbl_name WHERE col1=val1;SELECT * FROM tbl_name WHERE col1=val1 AND col2=val2;/* do not use an index */SELECT * FROM tbl_name WHERE col2=val2;SELECT * FROM tbl_name WHERE col2=val2 AND col3=val3; B-tree索引树在数据库索引中很常用的树数据结构。它始终保持数据有序，从而能够快速查找完全匹配(等于运算符)和范围(例如，大于，小于和BETWEEN运算符)。这种类型的索引可用于大多数存储引擎，例如InnoDB和MyISAM。 因为B树节点可以有许多子节点，所以B树与二叉树不同，二叉树每个节点限制为2个子节点。 与哈希索引形成对比，哈希索引仅在MEMORY存储引擎中可用。MEMORY存储引擎也可以使用B树索引，如果某些查询使用范围运算符，则应为MEMORY表选择B树索引。 术语B树的使用旨在作为一般索引设计类的参考。由于经典B树设计中不存在的复杂性，MySQL存储引擎使用的B树结构可以被视为变体。 hash索引哈希索引仅能用于相等运算符的查询，而不能用于范围运算符(如大于或BETWEEN)。它可用于MEMORY表。尽管由于历史原因，哈希索引是MEMORY表的默认值，但该存储引擎还支持B树索引，这对于通用查询来说通常是更好的选择。MySQL包含此索引类型的变体，即自适应哈希索引，如果需要，它将根据运行时条件自动构建InnoDB表。 参考文献How MySQL Uses IndexesComparison of B-Tree and Hash IndexesMultiple-Column Indexes","categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.sugarmix.me/categories/数据库/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.sugarmix.me/tags/翻译/"},{"name":"MySQL","slug":"MySQL","permalink":"https://blog.sugarmix.me/tags/MySQL/"}]},{"title":"MySQL存储引擎的特点","slug":"20190225173604","date":"2019-02-25T09:36:09.000Z","updated":"2020-04-07T08:02:20.251Z","comments":true,"path":"20190225173604/","link":"","permalink":"https://blog.sugarmix.me/20190225173604/","excerpt":"每个MySQL存储引擎都满足特定需求。因此，引擎的选择主要取决于您希望在应用程序中完成的任务。 每个存储引擎的完整功能超出了本文的范围。我们将仅讨论各种存储引擎的不同以及它们的适应场景。","text":"每个MySQL存储引擎都满足特定需求。因此，引擎的选择主要取决于您希望在应用程序中完成的任务。 每个存储引擎的完整功能超出了本文的范围。我们将仅讨论各种存储引擎的不同以及它们的适应场景。 InnoDB存储引擎InnoDB用于大多数数据库服务器，因为它支持事务，符合ACID。 原子性是增强数据库中数据的完整性的一种特性。当影响多个表的事务发生时，必须全部完成，否则回滚。 一致性意味着数据在保存到磁盘之前能够通过验证规则。 隔离性允许数据库隔离来自不同并发用户的事务。 持久性可确保在事务完成后被保存。 因此，如果您的应用程序需要上述功能，请选择InnoDB。 InnoDB的另一大优势是支持外键约束。这样可以保持所有相关数据库表的完整性。检查插入，更新和删除操作以确保多个表之间保持一致。 由于其持续改进，InnoDB不太容易发生数据库崩溃。如果在事务完成之前出现了问题，服务器重启后，InnoDB将完成操作或撤消更改。 InnoDB支持B-Tree索引和FULLTEXT索引，底层分别使用B-Tree和Inverted Lists实现。 MyISAM存储引擎对于那些读取操作比写入操作更多的应用，MyISAM具有更好的性能。对于初学者来是很容易设计和创建一个数据库，因为它不支持外键(foreign keys)。使用外键需要有经验的配置来避免不合法的删除和更新操作。 与InnoDB相比，该引擎占用更少的磁盘空间，因此适用于磁盘空间受限制的应用。 MyISAM不符合ACID，因此它没有回滚功能。当事务失败时，必须手动删除数据。这个引擎支持并发插入操作。 MyISAM支持R-Tree索引。 CSV存储引擎CSV代表逗号分隔值(Comma Separated Values)。这个引擎保存用逗号分割的明文数据。 当创建表格的时候会自动创建一个 .CSV 文件。 CSV文件的例子如下 12&quot;75521&quot;,&quot;JOHN DOE&quot;&quot;75522&quot;,&quot;BABY DOE&quot; 这个引擎的唯一优点是容易被Office软件读取。 CSV引擎不支持索引和事务，很少被使用。 NDB存储引擎NDB 代表网络数据库(Network DataBase).它用于需要高级别可用性的集群环境中。NDB使用无共享体系结构，适用于创建分布式容错数据库体系结构。 如果你在运行一个至关重要(mission critical)的应用，并且数据需要冗余备份，选择NDB。然而，这个引擎需要一系列服务器来保存冗余数据。 大多数软件仓库的MySQL默认不安装这个引擎，需要下载MSQL社区版。 NDB具有InnoDB的大部分功能，可以扩展到128TB（7.5.2版本）。在线时间为99.999％，故障节点的恢复时间不到一秒。 Blackhole存储引擎黑洞引擎接受数据并将其丢弃。您可以使用此存储引擎创建表并向其插入数据，但后续读取将返回空集。引擎支持索引。 Blackhole引擎可用于验证转储文件语法并测量二进制日志记录的开销，甚至可以查找数据库中的性能瓶颈。 Memory存储引擎内存存储引擎用于将数据存储在内存中以用于特殊目的。使用此引擎容易崩溃，它的数据应该来源于其他永久存储的表。 内存存储引擎支持索引和加密。表中数据的大小受限于服务器上的可用内存。 可以使用此引擎存储非关键任务数据，例如会话(session)管理信息或只需最少更新的只读数据。请注意，重新启动服务器将擦除所有数据。 Archive存储引擎如果你想在数据库中存储很多不常被使用的数据，例如历史信息，请使用存档存储引擎。该引擎使用非常小的空间中存储大量信息。 它支持压缩和加密，但缺少索引和事务功能。因此，它仅适用于归档数据，不应该被用于需要被快速更改、需要大量读写的信息。 Federated存储引擎从没有集群和复制技术的远程MySQL服务器获取数据时，适合使用联合(Federated)存储引擎。 如果从使用联合引擎定义的本地表查询数据，则会从定义的远程服务器自动检索数据。因此，联合表需要本地和远程服务器。 远程服务器保存表定义和关联数据，而本地服务器仅保存包含指向远程服务器的连接字符串的定义。远程服务器上的存储引擎可以是任何类型，例如InnoDB或MyISAM。 MySQL默认不支持此引擎，使用需要启动。 联合存储引擎可以用作将数据写入远程服务器的代理。它只是一个指向远程服务器中另一个表的表。它应该很少被使用，因为它在连接表时非常慢并且在涉及事务时具有奇怪的行为。 参考文献How to Choose MySQL Storage Engine on Alibaba Cloud","categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.sugarmix.me/categories/数据库/"}],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://blog.sugarmix.me/tags/翻译/"},{"name":"MySQL","slug":"MySQL","permalink":"https://blog.sugarmix.me/tags/MySQL/"}]},{"title":"内存数据存储系统Redis与Memcached对比","slug":"20190220102211","date":"2019-02-20T02:22:11.000Z","updated":"2020-04-07T08:02:20.251Z","comments":true,"path":"20190220102211/","link":"","permalink":"https://blog.sugarmix.me/20190220102211/","excerpt":"Redis和Memcached都是内存数据存储系统。Redis将大部分数据存储在内存中。它支持多种数据类型，包括字符串，哈希表和链列等。在本文中，我们将研究Redis和Memcached之间的区别。","text":"Redis和Memcached都是内存数据存储系统。Redis将大部分数据存储在内存中。它支持多种数据类型，包括字符串，哈希表和链列等。在本文中，我们将研究Redis和Memcached之间的区别。 功能比较Redis的作者对Redis和Memcached有如下比较： 服务器端数据操作Redis拥有更多数据结构，支持服务端(Redis服务)直接对数据进行操作(如对整数的+1和-1操作)。对于类似的操作，在Memcached中，需要将数据复制到客户端，修改后，在服务端(Memcached服务)重新设置该值。这极大地增加了网络IO。在Redis中，这些复杂的操作与一般的GET/SET操作一样高效。因此，如果您需要缓存来支持更复杂的结构和操作，Redis是一个不错的选择。 内存使用效率比较由于使用了简单的键值存储，Memcached具有更高的内存利用率。但是，如果Redis采用哈希结构，由于其组合压缩模式，它将具有比Memcached更高的内存利用率。 性能比较Redis仅使用单核，而Memcached使用多核。因此，在一般情况下，就核心而言，Redis在小型数据存储方面的性能高于Memcached。在存储10万(100k)条及以上的数据时，Memcached优于Redis。虽然Redis也对存储大数据进行了一些优化，但它仍然不如Memcached。 现在做一些支持上述观点的讨论。 对不同数据类型的支持Memcached仅支持简单键值结构的数据记录，Redis支持更丰富的数据类型，包括String，Hash，List，Set和Sorted Set。Redis在内部使用redisObject来表示所有键和值。redisObject的主要信息如下所示：该类型表示值对象的数据类型。编码指示Redis中不同数据类型的存储方法，例如type = string表示该值存储一般字符串，相应的编码可以是raw或int。如果为int，则Redis将关联的字符串存储并表示为值类型。当然，前提是可以用值表示字符串，例如字符串“123”和“456”。只有启用Redis虚拟内存功能后，才会为内存分配vm字段。默认情况下此功能处于关闭状态。现在让我们讨论一些数据类型。 String常用命令：set/get/decr/incr/mget等。应用场景：String是最常见的数据类型，通用key/value属于此类别。实现方法：String是字符串，redisObject默认情况下使用String(被保存的数据都被视为字符串)。当调用INCR或DECR操作时，系统会将其转换为值类型以进行计算(只有进行数值计算时，才将字符串类型转换为数值类型)。此时，redisObject的编码字段为int。 Hash常用命令：hget/hset/hgetall等。应用场景：存储用户信息对象数据，包括用户ID，用户名，年龄和生日;通过用户ID检索用户名，年龄或生日。实现方法：Redis中的Hash是内部存储值的HashMap，并提供直接访问此map成员的接口。如图所示，Key是用户ID，Value是map。此映射的键是成员属性名称，值是属性值。通过这种方式，可以直接执行更改并通过内部映射的键访问数据（在Redis中，内部映射键称为字段），即通过密钥（用户ID）+字段（属性标记）到对相应的属性数据执行操作。 当前HashMap有两种实现方式：当HashMap中只有少数成员时，Redis会选择一维数组来实现紧凑存储以节省内存，而不是实际意义上的HashMap结构。此时，相应值redisObject的编码是zipmap。当成员数量增加时，Redis会将它们转换为真正意义上的HashMap，此时的编码将是ht。 List常用命令：lpush/rpush/lpop/rpop/lrange。应用场景：Redis List是Redis中最重要的数据结构。实际上，可以使用Redis的list结构实现Twitter的following list和fans list 。实现方法：通过双向链表，支持反向查找和遍历以方便操作。但它也带来了一些额外的内存开销。Redis中的许多实现（包括发送缓冲队列）也采用此数据结构。 Set常用命令：sadd/spop/smembers/sunion等。应用场景：Redis set提供了与list类似的外部列表功能。它的特殊之处在于set可以自动删除重复项。当您需要存储没有任何重复的数据list时，set是一个不错的选择。此外，set提供了一个重要的接口来判断一个成员是否在一个集合中，list不提供此功能。实现方法：set的内部实现是一个HashMap，其值始终为null。它实际上通过计算哈希值来快速删除重复项。实际上，这也是为什么set可以判断成员是否在集合内的原因。 Sorted Set常用命令：zadd/zrange/zrem/zcard等。应用场景：Redis Sorted Set(排序集)的应用场景与集合的应用场景类似。不同之处在于，set不会自动对数据进行排序，但是排序集可以通过用户提供的优先级参数对成员进行排序。而且，后者还会自动对插入的数据进行排序。当您需要一个没有重复数据的有序集合列表时，您可以选择Sorted Set数据结构，例如Twitter的公共时间线，它可以将发布时间作为优先级参数，并自动对按时间获取的数据进行排序。实现方法：Redis sorted set在内部使用HashMap和SkipList来确保高效的数据存储和排序。HashMap存储成员和优先级参数之间的映射;而SkipList存储所有成员。排序依赖于存储在HashMap中的优先级参数。使用SkipList结构可以提高搜索效率并简化实现。 不同的内存管理方案在Redis中，数据不一定完全保存在内存中。这是Redis和Memcached的主要区别。当物理内存已满时，Redis可能会将长时间未使用的值交换到磁盘。Redis仅缓存所有键(key)信息。如果发现内存使用率超过阈值，则会触发交换操作。Redis根据swappability = age * log(size_in_memory)计算要交换到磁盘的键的值。然后，将值保存到磁盘并从内存中擦除。此功能使Redis能够维护大于其机器内存容量的数据。机器内存必须保留所有键，并且不会把所有数据都交换到硬盘(内存中一定存在没有被交换的数据)。 当Redis进行数据交换时，提供服务的主线程和执行交换操作的子线程将共享这部分内存。此时Redis将阻止数据更新操作，直到子线程完成交换操作。当从Redis读取数据时，如果读取键对应的值不在内存中，则Redis需要从交换文件加载相应的数据，然后将其返回给请求者。这里存在I/O线程池的问题。默认情况下，Redis会拥塞，也就是说，只有在成功加载所有交换文件后才会响应。当有少量客户端时，此策略适用于成批操作。但是如果你在一个大型网站程序中应用Redis，它就无法满足高并发性要求。但是，可以设置Redis运行的I/O线程池大小，并使用并发读取加载位于交换文件的数据的请求，以缩短拥塞时间。 对于像Redis和Memcached这样基于内存的数据库系统，内存管理效率是影响系统性能的关键。在C语言中，malloc/free是最传统的分配和释放内存的方法。然而，这个方法隐藏了巨大的缺陷：首先，对于开发者来说，分配和释放不匹配很容易导致内存泄漏；其次，频繁的调用将使重新循环利用内存变得困难(内存碎片)，减少了内存的利用率；最后，系统调用将比一般函数调用消耗更大的系统开销。因此，为了提高内存管理效率，内存管理不会直接使用malloc/free调用作为解决方案。Redis和Memcached都采用他们自己设计的内存管理机制，但实现方法差异很大。接下来我们介绍这两种机制。 默认情况下，Memcached使用Slab Allocation机制进行内存管理。其主要思想是将分配的内存分段为预定义的特定长度的块，用这些块来存储长度相匹配的键值数据记录，以完全解决内存片段(外碎片)问题。理想状态下，slab的分配机制设计应该满足外部数据存储的需求，也就是说，它有助于在Slab Allocation系统中存储所有不同长度的键值数据。但是，Memcached的其他内存请求申请是通过一般的malloc/free调用发生的。通常，这些请求的数量小，频率低，不会影响整体系统性能。Slab Allocation的原理非常简单。首先它从操作系统申请一大块内存，把他们分成一系列大小不同的小块，然后把相同大小的小块放到Slab Class中。其中，块是用于存储键值数据的最小单元。通过在Memcached启动时创建增长因子，可以控制每个Slab类的大小。假设图中的生长因子是1.25。如果第一组中的块大小为88字节，则第二组中的块将为112字节。其余的块遵循相同的规则。当Memcached接收到客户端发送的数据时，首先根据数据大小选择最合适的Slab Class，然后在Memcached中查询包含Slab Class的空闲块列表，以找到用于存储数据的块。当一段数据过期或废弃被丢弃时，回收占用的块，并将其恢复到空闲列表。 从上面的过程中，我们可以看到Memcached具有非常高的内存管理效率，不会导致内存碎片。然而，它最大的缺点是它可能造成空间浪费。由于操作系统会在特定长度的内存空间中分配每个块，因此较长的数据可能无法完全利用该空间。如图所示，当我们将100字节的数据缓存到128字节的块中时，未使用的28字节会浪费掉。 Redis的内存管理的实现主要通过源代码中的两个文件zmalloc.h和zmalloc.c来完成。为了便于内存管理，Redis会在内存分配后将内存大小存储在内存块头中。如图所示，real_ptr是Redis调用malloc后返回的指针。Redis将内存块大小存储在头中，并且内存占用的大小是可确定的，即系统返回size_t类型的长度，然后返回ret_ptr。当需要释放内存时，系统将ret_ptr传递给内存管理程序。通过ret_ptr，程序可以轻松计算real_ptr的值，然后通过real_ptr释放内存。Redis通过定义长度为ZMALLOC_MAX_ALLOC_STAT的数组来记录所有内存的分布。数组中的每个元素表示当前程序分配的内存块数，内存块的大小是元素的下标。在源代码中，此数组是zmalloc_allocations。zmalloc_allocations[16]表示以16字节长度分配的内存块数。zmalloc.c包含一个used_memory的静态变量，用于记录当前分配的内存的总大小。所以一般来说，Redis采用封装的malloc/free，与Memcached的内存管理机制相比要简单得多。 数据持久性支持虽然是基于内存的存储，但Redis支持内存数据持久性，并提供两种主要的持久性策略：RDB快照和AOF日志。Memcached不支持数据持久性操作。 RDB快照Redis支持将当前数据的快照存储到数据文件中以实现持久性，即RDB快照。但是，我们如何为连续写入数据的数据库生成快照呢？Redis利用fork命令的copy on write机制。在创建快照时，当前进程会fork一个子进程，使所有数据循环并将它们写入RDB文件。我们可以通过Redis的save命令配置RDB快照生成的时间。例如，如果要每10分钟配置一次快照生成，则可以在每1,000次写入后配置快照生成。您还可以配置多个规则以便一起实施。这些规则的定义在Redis的配置文件中。您还可以在Redis运行期间使用Redis的CONFIG SET命令设置规则，而无需重新启动Redis。 Redis的RDB文件在某种程度上是不可破坏的，因为它在新进程中执行其写操作。生成新的RDB文件后，Redis生成的子进程将首先将数据写入临时文件，然后通过原子重命名系统调用将临时文件重命名为RDB文件，以便RDB文件在Redis发生错误后始终可用。同时，Redis的RDB文件也是Redis主从同步内部实现的一个链接。但是，RDB的缺点在于，一旦数据库遇到某些问题，保存在RDB文件中的数据可能不是最新的，从最后一个RDB文件生成到Redis失败期间数据丢失。请注意，对于某些企业来说，这是可以容忍的。 AOF日志AOF日志的全程是 Append Only File。它是一个附加的日志文件。与通用数据库的binlog不同，AOF是一个可识别的明文(recognizable plaintext)，其内容是Redis标准命令。Rdeis仅把引起数据更改的命令添加到AOF。每个更改数据的命令都会生成一个日志。AOF文件将变得越来越大。Redis提供了另一个功能-AOF重写。AOF重写的功能是重新生成AOF文件。新AOF文件中，每条记录只有一个操作，而不像在旧的AOF文件中那样，记录了对同一个值的多次操作。生成过程类似于RDB快照，即分支进程，遍历数据并将数据写入新的临时AOF文件。将数据写入新文件时，它会将所有写操作日志写入旧的AOF文件，并同时将它们记录在内存缓冲区中。完成操作后，系统会一次将缓冲区中的所有日志写入临时文件。此后，它将调用atomic rename命令以使用新的AOF文件替换旧的AOF文件。 AOF是写文件操作，旨在将操作日志写入磁盘。它还涉及我们前面提到的写操作过程。在Redis调用AOF的写入操作后，它使用appendfsync选项通过调用fsync命令来控制将数据写入磁盘的时间。以下appendfsync中的三个设置选项具有从低到强的安全强度。 appendfsync no：当我们将appendfsync设置为no时，Redis不会主动调用fsync来将AOF日志同步到磁盘。同步将完全依赖于操作系统调试。大多数Linux操作系统每30秒执行一次fsync操作，以将缓冲区中的数据写入磁盘。 appendfsync everysec：当我们将appendfsync设置为everysec时，Redis将默认每隔一秒调用一次fsync，以将缓冲区中的数据写入磁盘。但是当fsync调用持续时间超过1秒时，Redis将采用fsync延迟等待一秒钟。也就是说，Redis将在两秒后调用fsync。无论执行多长时间，它都将执行此fsync。此时，由于文件描述符在文件fsync期间会遇到拥塞，因此当前的写操作将遇到类似的拥塞。结论是，在绝大多数情况下，Redis将每隔一秒执行一次fsync。在最坏的情况下，它将每两秒执行一次fsync操作。大多数数据库系统将此操作称为组提交，即将多个写入的数据组合在一起并一次将日志写入磁盘。 appednfsync always：当我们将appendfsync设置为always时，每次写操作都会调用fsync一次。这时，数据是最安全的。当然，由于它每次都执行fsync，因此会影响性能。 对于一般业务需求，我们建议您使用RDB进行持久化，因为RDB开销远低于AOF日志。对于无法承受任何数据丢失风险的应用程序，我们建议您使用AOF日志。 集群管理的差异Memcached是一个全内存数据缓冲系统。虽然Redis支持数据持久性，但全内存是其高性能的本质。对于基于内存的存储，物理机的内存大小是系统的最大数据存储容量。如果要处理的数据大小超过单个计算机的物理内存大小，则需要构建分布式群集以扩展存储容量。 Memcached本身不支持分布式模式。您只能通过分布式算法(如Consistent Hash)在客户端实现Memcached的分布式存储。下图演示了Memcached的分布式存储实现架构。在客户端向Memcached集群发送数据之前，它首先通过嵌套分布式算法计算数据的目标节点，然后嵌套分布式算法直接将数据发送到节点进行存储。但是当客户端查询数据时，还需要计算用作查询数据位置的节点，然后直接将查询请求发送到节点以获取数据。 与只能在客户端实现分布式存储的Memcached相比，Redis更喜欢在服务器端构建分布式存储。最新版本的Redis支持分布式存储。Redis Cluster是Redis的高级版本，可实现分布式存储并允许SPOF。它没有中心节点，能够进行线性扩展。下图提供了Redis Cluster的分布式存储架构。节点间通信遵循二进制协议，但节点 - 客户端通信遵循ASCII协议。在数据放置策略中，Redis Cluster将整个密钥数值范围划分为4,096个散列槽，并允许在每个节点上存储一个或多个散列槽。也就是说，当前的Redis群集最多支持4,096个节点。Redis Cluster使用的分布式算法也很简单：crc16（key）％HASH_SLOTS_NUMBER。 结论在本文中，我们讨论了Redis和Memcached之间的差异。我们首先列出了Redis的作者Salvatore Sanfilippo提出的几点比较。此后，我们进一步阐述了Redis和Memcached之间的关键点，即支持的数据类型，集群管理，数据持久性支持和内存管理方案。 参考原文：Redis vs. Memcached: In-Memory Data Storage Systems","categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.sugarmix.me/categories/数据库/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://blog.sugarmix.me/tags/Redis/"},{"name":"Memcached","slug":"Memcached","permalink":"https://blog.sugarmix.me/tags/Memcached/"},{"name":"翻译","slug":"翻译","permalink":"https://blog.sugarmix.me/tags/翻译/"}]},{"title":"批量修改Hexo文件名","slug":"20181229230044","date":"2018-12-29T15:00:44.000Z","updated":"2020-04-07T08:02:20.251Z","comments":true,"path":"20181229230044/","link":"","permalink":"https://blog.sugarmix.me/20181229230044/","excerpt":"众所周知Hexo是个纯静态页面生成工具，使用hexo new title可生成标题为title的文章。若文章题目中出现中文，编码后肉眼不可识别中文意思；若不转码，中文作为url的一部分总会出现种种问题。本文将阐述解决上述问题的方法。","text":"众所周知Hexo是个纯静态页面生成工具，使用hexo new title可生成标题为title的文章。若文章题目中出现中文，编码后肉眼不可识别中文意思；若不转码，中文作为url的一部分总会出现种种问题。本文将阐述解决上述问题的方法。 第一种，在创建文章的时候有意识的使用英文标题。第二中，使用当前时间作为文件名(即URL中的地址)，新建文件后再从文件中修改标题。 本文对第二种方法进行介绍，使用脚本创建新文章，注意时间是精确到秒，该脚本放在博客的根目录 12345#!/bin/bashDATE=date +%Y%m%d%H%M%Shexo new \"$DATE\"vim source/_posts/$DATE.md 但是问题来了，如果已经写了很多很多的文章了，而且想批量修改成上述格式怎么办呢？下面给出批量修改文件名的脚本，将此脚本放到_post目录，执行即可，最终文件的格式将与上述格式相同 1234567891011121314151617181920212223ls | grep \".md\" &gt; filename.txtnum=`cat filename.txt|wc -l`echo \"Start\"for((i=1;i&lt;=$num;i++));do filename=`cat filename.txt|awk NR==$i` date=`cat $filename|grep \"date: \"` year=`echo $date|cut -c 7-10` mon=`echo $date|cut -c 12-13` day=`echo $date|cut -c 15-16` hour=`echo $date|cut -c 18-19` min=`echo $date|cut -c 21-22` sec=`echo $date|cut -c 24-25` oldname=`echo $&#123;filename%.md&#125;` newname=$year$mon$day$hour$min$sec mv $oldname $newname mv $oldname.md $newname.md echo \"Renamed Number: $i\"doneecho \"Done\" 执行此脚本时，同时会重命名放图片的文件夹，若该文件夹不存在，则会有一系列输出，正常情况不要慌。 此时默认生成的链接里，会出现两部分日期，修改配置文件_config.yml 1permalink: :title/ 因为修改了文章链接，所有依赖链接工作的工具都会收影响，比如访客计数，评论系统等等。 最后提一句，不要在Telegram里直接保存代码，bash中的反引号会被处理掉。","categories":[{"name":"网站","slug":"网站","permalink":"https://blog.sugarmix.me/categories/网站/"}],"tags":[{"name":"网站","slug":"网站","permalink":"https://blog.sugarmix.me/tags/网站/"}]},{"title":"霍夫变换检测原理及Python实现","slug":"20180415221531","date":"2018-04-15T14:15:31.000Z","updated":"2020-04-07T08:02:20.251Z","comments":true,"path":"20180415221531/","link":"","permalink":"https://blog.sugarmix.me/20180415221531/","excerpt":"随着人工智能的兴起，计算机视觉相关概念，如人脸识别、人脸检测逐渐进入大众视野。本篇文章介绍计算机视觉中最基础的知识，直线和圆的一种检测算法-霍夫变换。并在最后给出Python的样例代码。","text":"随着人工智能的兴起，计算机视觉相关概念，如人脸识别、人脸检测逐渐进入大众视野。本篇文章介绍计算机视觉中最基础的知识，直线和圆的一种检测算法-霍夫变换。并在最后给出Python的样例代码。 综述霍夫变换用来检测物图像中的特征(例如直线和圆).算法如下： 根据被检测的图形，寻找特定的参数空间原图像中所有的点在参数空间中执行投票,投票结果最大的点，即为要寻找的图形 根据上面的描述不难看出,一般情况下： 不同图形的参数空间不同参数空间中的一个点可以表示原图像中的一个图形的所有信息 检测直线截距和斜率两个参数可以确定一条直线，但斜率无穷大甚至不存在时,无法在计算机中准确表示.所以在判定直线时,需要选定另一个参数空间 $$r=x\\cos \\theta +y\\sin \\theta$$ 此时任意一条直线均可以用$r$(直线到圆心的距离)和$\\theta$(嗯....不好描述看上图吧)唯一表示. 现在思考一个简单的问题，根据上述公式，已知两点$(x_1,y_1)$,$(x_2,y_2)$,能否确定$r$和$\\theta$,$\\theta\\subseteq \\left ( -\\frac{\\pi }{2} ,\\frac{\\pi }{2} \\right )$.如果不知道怎么确定就洗洗睡吧 也就是说，若已知图像中有且仅有一条直线，且不考虑像素带来的偏差(即所有点的坐标都是实数),则可以根据(直线上的)两点确定直线的具体位置. 上述过程是求解一个二元一次方程组.方程组中的每个方程代表一条曲线.解为两条曲线交点. 如果在同一条直线上选取三个点,三个点在参数空间做出的曲线必然相交与同一点，且该点表示原图像中的一条直线.以此类推,原图中同一直线上所有点在参数空间中做出的所有曲线必定相交与一点 以上讨论是基于所有坐标均为实数,在实际中,像素为整数,无法在参数空间做出一条真正连续的曲线,最精确的近似是在参数空间做出连续的像素点.所以要将上述连续过程离散化.离散化后的曲线所经过的像素点,就是其投票的点.多条曲线的交点,必然是得票数最高的点.用得票数最高的点代替连续曲线的交点,此时该点为检测出的直线对应的参数点.至此,完成直线检测 因为存在误差,所以投票后的点会集中在一个区域,而不是某个特定的点,这也就解释了为什么会检测出多条几乎重叠的曲线. 上述描述中,基于这样一个假设,即图像中的所有点非黑即白,现实中的图像并非如此,所以在霍夫变换检测前,一般先进行边缘检测,边缘检测后返回的图像就是非黑即白(是边缘,或者不是边缘). 检测圆就像开头提到的,检测圆与检测直线有着不同的参数空间.其他过程与检测直线完全相同 $x=x_0+r\\cos\\theta$$y=y_0+r\\sin\\theta$ 我们假定知道所需检测的圆的半径$r$.以原图像中的点为圆心,以$r$为半径在参数空间做圆,投票最多的点即为圆心,因为已知半径,圆检测完成.上述假设已知半径.实际使用中,只需给出半径的范围,并遍历之,在所有遍历结果中找投票数最大的,即为被检测的圆 下图中,半径为$r$的红圆为期待被检测到的圆,每个蓝色的圆均是以红圆周上的点为圆心,以$r$为半径得到的圆,重叠部分最多的点即为被检测圆的圆心. Python实现由于时间原因,此处仅给出openCV中霍夫变换检测直线和圆的样例. 参考Hough Line Transform霍夫变换","categories":[{"name":"图像","slug":"图像","permalink":"https://blog.sugarmix.me/categories/图像/"}],"tags":[{"name":"图像","slug":"图像","permalink":"https://blog.sugarmix.me/tags/图像/"},{"name":"openCV","slug":"openCV","permalink":"https://blog.sugarmix.me/tags/openCV/"}]},{"title":"关系模式符合的范式","slug":"20180319190418","date":"2018-03-19T11:04:18.000Z","updated":"2020-04-07T08:02:20.251Z","comments":true,"path":"20180319190418/","link":"","permalink":"https://blog.sugarmix.me/20180319190418/","excerpt":"做事情都要有其特定的规范，按照规范做事，可以避免再去踩前辈们踩过的坑。本文将讨论在数据库设计时，应该遵循的规范。符合规范的层次越高，设计越复杂。真正使用时，需要考虑项目本身的复杂度，权衡好利弊。并不一定符合的层次越高，就是越好的设计。","text":"做事情都要有其特定的规范，按照规范做事，可以避免再去踩前辈们踩过的坑。本文将讨论在数据库设计时，应该遵循的规范。符合规范的层次越高，设计越复杂。真正使用时，需要考虑项目本身的复杂度，权衡好利弊。并不一定符合的层次越高，就是越好的设计。 按规范设计的好处减少冗余。设计不良的数据表，存在大量冗余数据，这些数据浪费磁盘空间，还会影响数据修改的效率。下文讲看到冗余的例子。 增强一致性。存在冗余数据越多，越容易造成数据不一致。接下来将逐渐增强对一致性的要求，不同层次的要求就出现了不同的范式。 一些定义候选码若关系中的某一 属性组 的值能唯一的标识一个元组,而其任何真子集都不能再标识,则称该属性组为候选码。下文中不加解释的 码 即为候选码。 主属性包含在任意候选码中的属性 主码候选码中任选一组，均可作为主码。 非主属性不包含在主码中的属性，选定主码后确定非主属性。 非主属性 不等于 不是主属性的属性 函数依赖B可以由A导出.则B依赖A $$A \\to B$$ 完全函数依赖B可以由A导出,并且不能由A的任意子集导出,则B完全函数依赖A $$(A \\to B)\\land(\\lnot((\\exists C \\subsetneq A)\\land(C \\to B)))$$ 部分函数依赖B可以由A导出,并且能由A的某个真子集导出,则B部分函数依赖A $$(A \\to B)\\land((\\exists C \\subsetneq B)\\land(C \\to B))$$ 传递函数依赖B可以由A导出,C可以由B导出,则C传递函数依赖A $$(A \\to B)\\land(B \\to C)$$ 第一范式定义域都应该是原子性的 举例假如属性存在以下依赖关系 123学号 → 学生姓名课程号 → 课程名 → 教材(学号,课程名) → 分数 能放到数据库的信息都符合第一范式,下面给出一个符合第一范式的例子 1成绩(学号,学生姓名,课程号,课程名,教材,分数) 根据定义主码:(学号,课程号)非主属性:学生姓名,课程名,教材,分数 第二范式定义在第一范式的基础上，非码属性必须完全依赖于候选码(在第一范式基础上消除非主属性对主码的部分函数依赖) 举例学生姓名依赖学号却不依赖课程号,所以非主属性(学生姓名)部分依赖主码(学号,课程号).修改第一范式的例子使其符合第二范式 123学生(学号,学生姓名)课程(课程号,课程名,教材)成绩(学号,课程号,分数) 第三范式官方定义任何非主属性不依赖于其它非主属性（在第二范式基础上消除传递依赖） 举例在第二范式中的课程(课程号,课程名,教材)存在课程号 → 课程名 → 教材依赖关系,非主属性(教材)传递依赖非主属性(课程号).修改例子使其满足第三范式 1234学生(学号,学生姓名)课程(课程号,课程名)教材(课程名,教材)成绩(学号,课程号,分数) BC范式定义在第三范式基础上，任何非主属性(其中包含主属性,神奇不神奇)不能对主码子集依赖(在第三范式基础上消除对主码子集的依赖). 知乎上大佬给出的一个更精确的定义:消除主属性对于码的部分与传递函数依赖. 因为第三范式已经解决其他依赖,此处只要解决那些原本可以被选为主码却沦为了非主属性的的主属性们,也就是说,此时,非主属性依旧是主属性. 举例下面这个例子抄自知乎某公司有若干个仓库: 每个仓库只能有一名管理员一名管理员只能在一个仓库中工作一个仓库中可以存放多种物品一种物品也可以存放在不同的仓库中每种物品在每个仓库中都有对应的数量 关系仓库(仓库名,管理员,物品名,数量)符合第三范式 仓库 → 管理员管理员 → 仓库(仓库名,物品名) → 数量 若选(仓库名,物品名)为主码,则主属性(管理员)部分依赖主码(依赖主码中的仓库名) 修改关系使其符合BC范式 12仓库（仓库名，管理员）库存（仓库名，物品名，数量） 参考文献解释一下关系数据库的第一第二第三范式？ - 刘慰的回答 - 知乎","categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.sugarmix.me/categories/数据库/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://blog.sugarmix.me/tags/数据库/"}]}]}